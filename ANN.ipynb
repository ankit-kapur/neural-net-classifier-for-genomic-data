{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data_percentage = 70\n",
    "validation_data_percentage = 15\n",
    "test_data_percentage = 15\n",
    "\n",
    "directory_path = \"~/code/datamining/proj3/datasets\"\n",
    "\n",
    "file1 = directory_path + \"/project3_dataset1.txt\"\n",
    "file2 = directory_path + \"/project3_dataset2.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from __future__ import division\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from scipy.io import loadmat\n",
    "from math import sqrt\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame, Panel\n",
    "\n",
    "# ============ Configurable parameters ============ #\n",
    "\n",
    "# MAT file path\n",
    "mat_file_path = 'mnist_all.mat'\n",
    "# CSV file path\n",
    "csv_file_path = 'backprop_results.csv'\n",
    "\n",
    "# Percentage of training-data that we'll use for validation\n",
    "validation_data_percentage = 16.66667\n",
    "#validation_data_percentage = 80\n",
    "\n",
    "# Max number of iterations for minimization\n",
    "opts = {'maxiter' : 50}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49999, 713)\n",
      "(49999, 10)\n",
      "(10001, 713)\n",
      "(10001, 713)\n",
      "(10000, 713)\n",
      "(10000, 10)\n",
      "[[0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print train_data.shape\n",
    "print train_label.shape\n",
    "print validation_data.shape\n",
    "print validation_data.shape\n",
    "print test_data.shape\n",
    "print test_label.shape\n",
    "\n",
    "print test_label[5000:5003,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generateLabelVector(x):\n",
    "    vector = np.repeat(np.array([0]), 10, 0)\n",
    "    vector[x] = 1\n",
    "    return vector\n",
    "\n",
    "def doFeatureSelection(train_data, validation_data, test_data):\n",
    "\n",
    "    n_rows = train_data.shape[0]\n",
    "    n_cols = train_data.shape[1]\n",
    "    is_first_run = True\n",
    "    \n",
    "    new_train_data = train_data\n",
    "    new_validation_data = validation_data\n",
    "    new_test_data = test_data\n",
    "    \n",
    "    if train_data.shape[0]!=0:\n",
    "        for i in range(n_cols):\n",
    "            \n",
    "            col_flag = False\n",
    "            temp = train_data[0][i]\n",
    "            \n",
    "            for j in range(1, n_rows):\n",
    "                if train_data[j][i] != temp:\n",
    "                    col_flag = True\n",
    "                    break\n",
    "            if col_flag is True:\n",
    "                if is_first_run is True:\n",
    "                    new_train_data = np.array([train_data[:, i]]) # create matrix \n",
    "                    new_train_data = np.reshape(new_train_data, (n_rows, -1))\n",
    "                    \n",
    "                    new_validation_data = np.array([validation_data[:, i]]) # create matrix \n",
    "                    new_validation_data = np.reshape(new_validation_data, (validation_data.shape[0], -1))\n",
    "                    \n",
    "                    new_test_data = np.array([test_data[:, i]]) # create matrix \n",
    "                    new_test_data = np.reshape(new_test_data, (test_data.shape[0], -1))\n",
    "                    \n",
    "                    is_first_run = False;\n",
    "                else:\n",
    "                    tempmatrix = np.reshape(np.array([train_data[:, i].T]), (train_data.shape[0],-1))\n",
    "                    new_train_data = np.append(new_train_data, tempmatrix, 1)\n",
    "                    \n",
    "                    tempmatrix = np.reshape(np.array([validation_data[:, i].T]), (validation_data.shape[0],-1))\n",
    "                    new_validation_data = np.append(new_validation_data, tempmatrix, 1)\n",
    "                    \n",
    "                    tempmatrix = np.reshape(np.array([test_data[:, i].T]), (test_data.shape[0],-1))\n",
    "                    new_test_data = np.append(new_test_data, tempmatrix, 1)\n",
    "        \n",
    "    return new_train_data, new_validation_data, new_test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------START - preprocess------------------\n",
      "('Time for preprocessing: ', 93.93089413642883)\n",
      "-------------------- End of preprocessing ------------------\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/castamere/.local/lib/python2.7/site-packages/ipykernel/__main__.py:77: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/home/castamere/.local/lib/python2.7/site-packages/ipykernel/__main__.py:78: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "def preprocess(file_path):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    print(\"\\n--------------------START - preprocess------------------\")\n",
    "    \"\"\" Input:\n",
    "     Although this function doesn't have any input, you are required to load\n",
    "     the MNIST data set from file 'mnist_all.mat'.\n",
    "    \n",
    "     Output:\n",
    "     train_data: matrix of training set. Each row of train_data contains \n",
    "       feature vector of a image\n",
    "     train_label: vector of label corresponding to each image in the training\n",
    "       set\n",
    "     validation_data: matrix of training set. Each row of validation_data \n",
    "       contains feature vector of a image\n",
    "     validation_label: vector of label corresponding to each image in the \n",
    "       training set\n",
    "     test_data: matrix of training set. Each row of test_data contains \n",
    "       feature vector of a image\n",
    "     test_label: vector of label corresponding to each image in the testing\n",
    "       set\n",
    "\n",
    "     Some suggestions for preprocessing step:\n",
    "     - divide the original data set to training, validation and testing set\n",
    "           with corresponding labels\n",
    "     - convert original data set from integer to double by using double()\n",
    "           function\n",
    "     - normalize the data to [0, 1]\n",
    "     - feature selection \"\"\"\n",
    "    \n",
    "    \n",
    "    # Load the MAT object as a Dictionary\n",
    "    #mat = loadmat('/home/harsh/canopy/ML/mnist_all.mat')\n",
    "    mat = loadmat(mat_file_path)\n",
    "    is_first_run = True\n",
    "\n",
    "    for i in range(0,10):\n",
    "        \n",
    "        # training_matrix - each row is a training example, each column is a \n",
    "        # pixel. Size: N x 784 where N is the number of training examples\n",
    "        training_matrix = np.divide(mat.get('train'+str(i)),255.0)\n",
    "        # test_matrix - size T x 784, where T is number of test data elements\n",
    "        test_matrix = np.divide(mat.get('test'+str(i)),255.0)\n",
    "          \n",
    "        \n",
    "        # =========== Create test-data matrix =========== #\n",
    "        \n",
    "        # How many test data elements are present in the data for this digit?\n",
    "        test_data_count = test_matrix.shape[0]\n",
    "        \n",
    "        # Make an array of repeated labels like [9,9,9,9,...]\n",
    "        label_vector = generateLabelVector(i)\n",
    "        repeated_labels_testdata = np.tile(label_vector, (test_data_count,1))\n",
    "                \n",
    "        if is_first_run:\n",
    "            # Create test-data matrix and label vector\n",
    "            test_data = np.array(test_matrix)\n",
    "            test_label = repeated_labels_testdata\n",
    "        else:\n",
    "            # Append to the test-data matrix and label vector\n",
    "            test_data = np.append(test_data, test_matrix, 0)\n",
    "            test_label = np.append(test_label, repeated_labels_testdata, 0) \n",
    "        \n",
    "        \n",
    "        \n",
    "        # =========== Create training & validation matrices =========== #\n",
    "        \n",
    "        # How many training examples are present in the data for this digit?\n",
    "        num_of_examples = training_matrix.shape[0]\n",
    "        # How many of the given examples will be used for validation\n",
    "        validation_size = round(num_of_examples * float(validation_data_percentage / 100))\n",
    "        training_size = num_of_examples - validation_size\n",
    "        \n",
    "        # Randomly split the data into a validation and a training part\n",
    "        random_range = range(num_of_examples)\n",
    "        perm = np.random.permutation(random_range)\n",
    "        validation_part = training_matrix[perm[0:validation_size],:]\n",
    "        training_part = training_matrix[perm[validation_size:],:]\n",
    "        \n",
    "        # Make an array of repeated labels like [9,9,9,9,...]\n",
    "        label_vector = generateLabelVector(i)\n",
    "        repeated_labels_train = np.tile(label_vector, (training_size,1))\n",
    "        repeated_labels_valid = np.tile(label_vector, (validation_size,1))\n",
    "        \n",
    "        if is_first_run:\n",
    "            # Create training-data matrix and label vector\n",
    "            train_data = np.array(training_part)\n",
    "            train_label = repeated_labels_train\n",
    "            # Create validation-data matrix and label vector\n",
    "            validation_data = np.array(validation_part)\n",
    "            validation_label = repeated_labels_valid\n",
    "        else:\n",
    "            # Append to the training-data matrix and label vector\n",
    "            train_data = np.append(train_data, training_part, 0)\n",
    "            train_label = np.append(train_label, repeated_labels_train, 0)\n",
    "            # Append to the validation-data matrix and label vector\n",
    "            validation_data = np.append(validation_data, validation_part, 0)\n",
    "            validation_label = np.append(validation_label, repeated_labels_valid, 0)\n",
    "         \n",
    "        # Not the first run anymore\n",
    "        is_first_run = False        \n",
    "   \n",
    "     \n",
    "    # Perform feature-selection on all 3 of the matrics\n",
    "    train_data, validation_data, test_data = doFeatureSelection(train_data, validation_data, test_data)\n",
    "        \n",
    "    print(\"Time for preprocessing: \",time.time() - start_time)\n",
    "    print(\"-------------------- End of preprocessing ------------------\")\n",
    "    return train_data, train_label, validation_data, validation_label, test_data, test_label\n",
    "    \n",
    "\n",
    "\n",
    "file1 = \"~/code/datamining/proj3/datasets/project3_dataset1.txt\"\n",
    "train_data, train_label, validation_data, validation_label, test_data, test_label = preprocess(file1);\n",
    "print \"Done.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def categorical_to_numeric(dataframe):\n",
    "    for i in range(len(dataframe.columns)):\n",
    "        val = dataframe[i].values[0]\n",
    "        if (isinstance(val, str) and not val.isdigit()):\n",
    "            column = dataframe[i].values\n",
    "            unique_values = np.unique(column)\n",
    "            mapper = {value: index for (index, value) in enumerate(unique_values)}\n",
    "\n",
    "            dataframe.replace({i: mapper}, inplace=True)\n",
    "    return dataframe\n",
    "\n",
    "def get_data_partitions(filepath):\n",
    "    # Make dataframe\n",
    "    df = pd.read_csv(filepath, delimiter=\"\\t\", header=None)\n",
    "\n",
    "    # Identify the categorical data columns and convert them to a numerical representation\n",
    "    df = categorical_to_numeric(df)\n",
    "\n",
    "    # Calculate sizes of paritions\n",
    "    size_of_dataset = df.shape[0]\n",
    "    train_size = int(training_data_percentage * size_of_dataset / 100.0)\n",
    "    validation_size = int(validation_data_percentage * size_of_dataset / 100.0)\n",
    "    test_size = int(test_data_percentage * size_of_dataset / 100.0)\n",
    "\n",
    "    # Shuffle the rows\n",
    "    df = df.iloc[np.random.permutation(len(df))]\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    # Make partitions\n",
    "    training_partition = df[:train_size].as_matrix()\n",
    "    validation_partition = df[train_size:train_size+validation_size].as_matrix()\n",
    "    test_partition = df[train_size+test_size:test_size+train_size+validation_size].as_matrix()\n",
    "\n",
    "    return training_partition, validation_partition, test_partition\n",
    "\n",
    "def get_labels(data):\n",
    "    label_column = data[:, -1]\n",
    "    zeros = [(1 if x==0 else 0) for x in label_column]\n",
    "    ones = [(0 if x==0 else 1) for x in label_column]\n",
    "    labels = np.column_stack((zeros, ones))\n",
    "    return labels\n",
    "\n",
    "def get_data(filepath):\n",
    "    training_partition, validation_partition, test_partition = get_data_partitions(filepath)\n",
    "\n",
    "    # Make label data\n",
    "    training_labels = get_labels(training_partition)\n",
    "    validation_labels = get_labels(validation_partition)\n",
    "    test_labels = get_labels(test_partition)\n",
    "\n",
    "    # Data (without the label column)\n",
    "    train_data = training_partition[:,:-1]\n",
    "    validation_data = validation_partition[:,:-1]\n",
    "    test_data = test_partition[:,:-1]\n",
    "\n",
    "     \n",
    "    # Perform feature-selection\n",
    "    train_data, validation_data, test_data = doFeatureSelection(train_data, validation_data, test_data)\n",
    "    \n",
    "    return train_data, training_labels, validation_data, validation_labels, test_data, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(398, 30)\n",
      "(94, 30)\n",
      "(86, 30)\n",
      "\n",
      "(398, 2)\n",
      "(94, 2)\n",
      "(86, 2)\n"
     ]
    }
   ],
   "source": [
    "train_data, training_labels, validation_data, validation_labels, test_data, test_labels = get_data(file1)\n",
    "\n",
    "print train_data.shape\n",
    "print validation_data.shape\n",
    "print test_data.shape\n",
    "\n",
    "print '\\n', training_labels.shape\n",
    "print validation_labels.shape\n",
    "print test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lambda = 0.00\n",
      "obj_val 1.35094494447\n",
      "obj_val 1.35094494447\n",
      "obj_val 2.37529846579\n",
      "obj_val 1.41369755587\n",
      "obj_val 1.25837932875\n",
      "obj_val 1.25755239615\n",
      "obj_val 1.25590450706\n",
      "obj_val 1.24980022885\n",
      "obj_val 1.2358107089\n",
      "obj_val 1.24839020087\n",
      "obj_val 1.22823182416\n",
      "obj_val 1.22646976847\n",
      "obj_val 1.22404733598\n",
      "obj_val 1.21594802441\n",
      "obj_val 1.22247785635\n",
      "obj_val 1.21383512197\n",
      "obj_val 1.1923755728\n",
      "obj_val 1.18738223878\n",
      "obj_val 1.18201428979\n",
      "obj_val 1.17218630874\n",
      "obj_val 1.14264990355\n",
      "obj_val 1.18065851442\n",
      "obj_val 1.1420419834\n",
      "obj_val 1.13854415226\n",
      "obj_val 1.23528733814\n",
      "obj_val 1.13420725352\n",
      "obj_val 1.13615325922\n",
      "obj_val 1.13229350603\n",
      "obj_val 1.12991170411\n",
      "obj_val 1.12697642072\n",
      "obj_val 1.12772677075\n",
      "obj_val 1.1255833806\n",
      "obj_val 1.12319903126\n",
      "obj_val 1.12228029291\n",
      "obj_val 1.11861901044\n",
      "obj_val 1.12376300386\n",
      "obj_val 1.11738641459\n",
      "obj_val 1.11520522277\n",
      "obj_val 1.11413647032\n",
      "obj_val 1.11362929091\n",
      "obj_val 1.11435501288\n",
      "obj_val 1.11231992114\n",
      "obj_val 1.11115049583\n",
      "obj_val 1.1100764197\n",
      "obj_val 1.10866170423\n",
      "obj_val 1.10678658254\n",
      "obj_val 1.10944883997\n",
      "obj_val 1.10630953911\n",
      "obj_val 1.10556999138\n",
      "obj_val 1.10527364338\n",
      "obj_val 1.10388528846\n",
      "obj_val 1.10188051843\n",
      "obj_val 1.10329601949\n",
      "obj_val 1.10112790937\n",
      "obj_val 1.10052046693\n",
      "obj_val 1.09945798336\n",
      "obj_val 1.09858121941\n",
      "obj_val 1.09516430729\n",
      "obj_val 1.09215320015\n",
      "obj_val 1.09019424903\n",
      "obj_val 1.08851361927\n",
      "obj_val 1.08321198935\n",
      "obj_val 1.08217556811\n",
      "obj_val 1.09204320932\n",
      "obj_val 1.08058799427\n",
      "obj_val 1.0828994558\n",
      "obj_val 1.08009128264\n",
      "obj_val 1.07964930051\n",
      "obj_val 1.07908939676\n",
      "obj_val 1.07877493636\n",
      "obj_val 1.07870192094\n",
      "obj_val 1.07849882574\n",
      "obj_val 1.07843734901\n",
      "obj_val 1.07806513444\n",
      "obj_val 1.07767595033\n",
      "obj_val 1.07739185645\n",
      "obj_val 1.07701899793\n",
      "obj_val 1.07656235137\n",
      "obj_val 1.07583135551\n",
      "obj_val 1.07554357305\n",
      "obj_val 1.08803954417\n",
      "obj_val 1.07547285807\n",
      "obj_val 1.0753500808\n",
      "obj_val 1.07521567454\n",
      "obj_val 1.07512242176\n",
      "obj_val 1.07505935094\n",
      "obj_val 1.07482167377\n",
      "obj_val 1.07474927031\n",
      "obj_val 1.0741455268\n",
      "obj_val 1.07211861136\n",
      "obj_val 1.06911091518\n",
      "\n",
      "Lambda = 0.10\n",
      "obj_val 1.35405838887\n",
      "obj_val 1.35405838887\n",
      "obj_val 2.37899582689\n",
      "obj_val 1.41682633793\n",
      "obj_val 1.26149523786\n",
      "obj_val 1.26069552981\n",
      "obj_val 1.25910121209\n",
      "obj_val 1.25317876877\n",
      "obj_val 1.23917924191\n",
      "obj_val 1.25090023879\n",
      "obj_val 1.23138686734\n",
      "obj_val 1.22972434302\n",
      "obj_val 1.22697562035\n",
      "obj_val 1.21813697028\n",
      "obj_val 1.23120778473\n",
      "obj_val 1.21712342912\n",
      "obj_val 1.19727174712\n",
      "obj_val 1.21591483986\n",
      "obj_val 1.18732283377\n",
      "obj_val 1.17638932411\n",
      "obj_val 1.16459972213\n",
      "obj_val 1.19041816097\n",
      "obj_val 1.15969885159\n",
      "obj_val 1.15173900061\n",
      "obj_val 1.14450737271\n",
      "obj_val 1.17321623902\n",
      "obj_val 1.14121559542\n",
      "obj_val 1.13927104581\n",
      "obj_val 1.13728575746\n",
      "obj_val 1.13407715176\n",
      "obj_val 1.13285068135\n",
      "obj_val 1.14366797785\n",
      "obj_val 1.13239949743\n",
      "obj_val 1.13160156473\n",
      "obj_val 1.13047869527\n",
      "obj_val 1.13169901656\n",
      "obj_val 1.12965344122\n",
      "obj_val 1.12835796638\n",
      "obj_val 1.12801528165\n",
      "obj_val 1.12620532948\n",
      "obj_val 1.12571110537\n",
      "obj_val 1.12515830539\n",
      "obj_val 1.12725245743\n",
      "obj_val 1.12486696339\n",
      "obj_val 1.12435742858\n",
      "obj_val 1.12392670232\n",
      "obj_val 1.12247881967\n",
      "obj_val 1.12189058066\n",
      "obj_val 1.11926299358\n",
      "obj_val 1.12226697203\n",
      "obj_val 1.11829810738\n",
      "obj_val 1.11691667479\n",
      "obj_val 1.11546877238\n",
      "obj_val 1.11486742765\n",
      "obj_val 1.11458940905\n",
      "obj_val 1.11362780751\n",
      "obj_val 1.11422053306\n",
      "obj_val 1.11324460033\n",
      "obj_val 1.11255439421\n",
      "obj_val 1.11147350863\n",
      "obj_val 1.10876404149\n",
      "obj_val 1.10808625887\n",
      "obj_val 1.10385161422\n",
      "obj_val 1.1067483695\n",
      "obj_val 1.10206584119\n",
      "obj_val 1.10042638539\n",
      "obj_val 1.10248286353\n",
      "obj_val 1.09998164812\n",
      "obj_val 1.09965767349\n",
      "obj_val 1.09924102857\n",
      "obj_val 1.09873544083\n",
      "obj_val 1.0989016325\n",
      "obj_val 1.09850118369\n",
      "obj_val 1.09834618893\n",
      "obj_val 1.09808098712\n",
      "obj_val 1.09782738593\n",
      "obj_val 1.09690298377\n",
      "obj_val 1.09573928039\n",
      "obj_val 1.09453959918\n",
      "obj_val 1.09267097815\n",
      "obj_val 1.09189583668\n",
      "obj_val 1.08920971661\n",
      "obj_val 1.08819777967\n",
      "obj_val 1.08740257547\n",
      "obj_val 1.08817939327\n",
      "obj_val 1.08656492836\n",
      "obj_val 1.08564794153\n",
      "obj_val 1.08538381959\n",
      "obj_val 1.08507635135\n",
      "\n",
      "Lambda = 0.20\n",
      "obj_val 1.35717183326\n",
      "obj_val 1.35717183326\n",
      "obj_val 2.3826893363\n",
      "obj_val 1.41995434829\n",
      "obj_val 1.26461087671\n",
      "obj_val 1.26383641561\n",
      "obj_val 1.26229181742\n",
      "obj_val 1.25653923562\n",
      "obj_val 1.24256141992\n",
      "obj_val 1.25344008402\n",
      "obj_val 1.23456326121\n",
      "obj_val 1.23271580505\n",
      "obj_val 1.22991407369\n",
      "obj_val 1.22111632397\n",
      "obj_val 1.22721516079\n",
      "obj_val 1.21988435668\n",
      "obj_val 1.20596649782\n",
      "obj_val 1.17629310128\n",
      "obj_val 1.18030444319\n",
      "obj_val 1.15103724268\n",
      "obj_val 1.17119316081\n",
      "obj_val 1.14421074414\n",
      "obj_val 1.1380410769\n",
      "obj_val 1.13867546293\n",
      "obj_val 1.13539086819\n",
      "obj_val 1.13184004983\n",
      "obj_val 1.12815822948\n",
      "obj_val 1.12549754024\n",
      "obj_val 1.12075907201\n",
      "obj_val 1.11884045999\n",
      "obj_val 1.11721245771\n",
      "obj_val 1.14717168437\n",
      "obj_val 1.11613248291\n",
      "obj_val 1.11449534808\n",
      "obj_val 1.11405030336\n",
      "obj_val 1.11384419923\n",
      "obj_val 1.11291132773\n",
      "obj_val 1.11129911965\n",
      "obj_val 1.11537506748\n",
      "obj_val 1.11099835962\n",
      "obj_val 1.11053650229\n",
      "obj_val 1.11034770956\n",
      "obj_val 1.10933727584\n",
      "obj_val 1.10879811839\n",
      "obj_val 1.10655271325\n",
      "obj_val 1.10838512847\n",
      "obj_val 1.1057577211\n",
      "obj_val 1.10485099468\n",
      "obj_val 1.10401977619\n",
      "obj_val 1.10260528846\n",
      "obj_val 1.10137719148\n",
      "obj_val 1.10103132067\n",
      "obj_val 1.09996849534\n",
      "obj_val 1.10276675121\n",
      "obj_val 1.09958063556\n",
      "obj_val 1.09892816062\n",
      "obj_val 1.09849237499\n",
      "obj_val 1.0975536261\n",
      "obj_val 1.09594127803\n",
      "obj_val 1.09494351003\n",
      "obj_val 1.09275413402\n",
      "obj_val 1.09259744186\n",
      "obj_val 1.09172689024\n",
      "obj_val 1.09058273638\n",
      "obj_val 1.09138237341\n",
      "obj_val 1.09014843756\n",
      "obj_val 1.08936535189\n",
      "obj_val 1.08782313098\n",
      "obj_val 1.09583541291\n",
      "obj_val 1.08737381167\n",
      "obj_val 1.08677708385\n",
      "obj_val 1.0865606822\n",
      "obj_val 1.08642697962\n",
      "obj_val 1.08594466319\n",
      "obj_val 1.0851496843\n",
      "obj_val 1.08470482426\n",
      "obj_val 1.08403812697\n",
      "obj_val 1.08384420816\n",
      "obj_val 1.08274347215\n",
      "obj_val 1.08394554707\n",
      "obj_val 1.08241396459\n",
      "obj_val 1.08201823426\n",
      "obj_val 1.08158772914\n",
      "obj_val 1.08106695399\n",
      "obj_val 1.08240107567\n",
      "obj_val 1.08096056889\n",
      "obj_val 1.08077894456\n",
      "obj_val 1.08060391695\n",
      "\n",
      "Lambda = 0.30\n",
      "obj_val 1.36028527766\n",
      "obj_val 1.36028527766\n",
      "obj_val 2.38637899581\n",
      "obj_val 1.42308158733\n",
      "obj_val 1.26772624536\n",
      "obj_val 1.2669750534\n",
      "obj_val 1.2654763137\n",
      "obj_val 1.25988133359\n",
      "obj_val 1.24595012635\n",
      "obj_val 1.25600951993\n",
      "obj_val 1.23774150851\n",
      "obj_val 1.23573265953\n",
      "obj_val 1.23304349059\n",
      "obj_val 1.2251219482\n",
      "obj_val 1.2163127878\n",
      "obj_val 1.19790823858\n",
      "obj_val 1.19935349234\n",
      "obj_val 1.18599653949\n",
      "obj_val 1.17880950052\n",
      "obj_val 1.16545492804\n",
      "obj_val 1.18177131679\n",
      "obj_val 1.16277287888\n",
      "obj_val 1.16518754617\n",
      "obj_val 1.15484594962\n",
      "obj_val 1.15182643231\n",
      "obj_val 1.14966970718\n",
      "obj_val 1.14671198464\n",
      "obj_val 1.14582218307\n",
      "obj_val 1.14480811018\n",
      "obj_val 1.14134169365\n",
      "obj_val 1.145654229\n",
      "obj_val 1.13876400358\n",
      "obj_val 1.17457984181\n",
      "obj_val 1.13811878186\n",
      "obj_val 1.13799590818\n",
      "obj_val 1.13676716768\n",
      "obj_val 1.13616078737\n",
      "obj_val 1.13322103931\n",
      "obj_val 1.13187137424\n",
      "obj_val 1.12500730469\n",
      "obj_val 1.12488540081\n",
      "obj_val 1.12391039745\n",
      "obj_val 1.13642453807\n",
      "obj_val 1.12251505626\n",
      "obj_val 1.12087833325\n",
      "obj_val 1.11848746855\n",
      "obj_val 1.11794381397\n",
      "obj_val 1.11435661747\n",
      "obj_val 1.13283772717\n",
      "obj_val 1.11408847912\n",
      "obj_val 1.11368014166\n",
      "obj_val 1.11355962599\n",
      "obj_val 1.11287639881\n",
      "obj_val 1.11236482722\n",
      "obj_val 1.1126068842\n",
      "obj_val 1.11216373688\n",
      "obj_val 1.11179153295\n",
      "obj_val 1.11117990112\n",
      "obj_val 1.11129167369\n",
      "obj_val 1.11073176372\n",
      "obj_val 1.1099740028\n",
      "obj_val 1.10934650106\n",
      "obj_val 1.10792732267\n",
      "obj_val 1.10576350488\n",
      "obj_val 1.10525951213\n",
      "obj_val 1.101093669\n",
      "obj_val 1.09924533043\n",
      "obj_val 1.09478401669\n",
      "obj_val 1.10382228445\n",
      "obj_val 1.09369650312\n",
      "obj_val 1.09174853853\n",
      "obj_val 1.08952567081\n",
      "obj_val 1.09448311972\n",
      "obj_val 1.08831490835\n",
      "obj_val 1.08696525093\n",
      "obj_val 1.08711391964\n",
      "obj_val 1.08630078942\n",
      "obj_val 1.08515291739\n",
      "obj_val 1.08394649435\n",
      "obj_val 1.0928114525\n",
      "obj_val 1.08364618785\n",
      "obj_val 1.08310045904\n",
      "obj_val 1.08242275794\n",
      "obj_val 1.08218055045\n",
      "obj_val 1.0817178744\n",
      "obj_val 1.08125022616\n",
      "obj_val 1.08096040651\n",
      "obj_val 1.08045479307\n",
      "obj_val 1.08000773586\n",
      "obj_val 1.08051988287\n",
      "obj_val 1.0796111954\n",
      "obj_val 1.07925330536\n",
      "obj_val 1.07939649951\n",
      "obj_val 1.07910023145\n",
      "\n",
      "Lambda = 0.40\n",
      "obj_val 1.36339872206\n",
      "obj_val 1.36339872206\n",
      "obj_val 2.39006480721\n",
      "obj_val 1.42620805539\n",
      "obj_val 1.27084134388\n",
      "obj_val 1.27011144312\n",
      "obj_val 1.26865469245\n",
      "obj_val 1.2632047931\n",
      "obj_val 1.24933866612\n",
      "obj_val 1.25860060072\n",
      "obj_val 1.2409050058\n",
      "obj_val 1.23865168106\n",
      "obj_val 1.23609102278\n",
      "obj_val 1.22888790617\n",
      "obj_val 1.22159629399\n",
      "obj_val 1.21231158841\n",
      "obj_val 1.20060577773\n",
      "obj_val 1.20177700053\n",
      "obj_val 1.19725746003\n",
      "obj_val 1.1918110632\n",
      "obj_val 1.18821993736\n",
      "obj_val 1.1825771022\n",
      "obj_val 1.17853423368\n",
      "obj_val 1.17143554276\n",
      "obj_val 1.16264743157\n",
      "obj_val 1.15122399115\n",
      "obj_val 1.15997695148\n",
      "obj_val 1.14499503593\n",
      "obj_val 1.14449910073\n",
      "obj_val 1.13721252111\n",
      "obj_val 1.14125047703\n",
      "obj_val 1.13478795316\n",
      "obj_val 1.13380500434\n",
      "obj_val 1.13319994426\n",
      "obj_val 1.13177212755\n",
      "obj_val 1.12994420187\n",
      "obj_val 1.12831688241\n",
      "obj_val 1.12934315695\n",
      "obj_val 1.12764516791\n",
      "obj_val 1.12649801694\n",
      "obj_val 1.12541228261\n",
      "obj_val 1.12392474158\n",
      "obj_val 1.12365436167\n",
      "obj_val 1.12080693898\n",
      "obj_val 1.12099937815\n",
      "obj_val 1.12028773793\n",
      "obj_val 1.11625696\n",
      "obj_val 1.11324959859\n",
      "obj_val 1.11169783011\n",
      "obj_val 1.11112235451\n",
      "obj_val 1.10823374037\n",
      "obj_val 1.10665472196\n",
      "obj_val 1.10606767079\n",
      "obj_val 1.10600491002\n",
      "obj_val 1.10506531358\n",
      "obj_val 1.10368684745\n",
      "obj_val 1.10245330119\n",
      "obj_val 1.10096797864\n",
      "obj_val 1.10020206575\n",
      "obj_val 1.0999064598\n",
      "obj_val 1.09932816728\n",
      "obj_val 1.09906105681\n",
      "obj_val 1.09892832023\n",
      "obj_val 1.09834113763\n",
      "obj_val 1.09817731359\n",
      "obj_val 1.09844930788\n",
      "obj_val 1.09783153888\n",
      "obj_val 1.09762306692\n",
      "obj_val 1.09735336193\n",
      "obj_val 1.09688258018\n",
      "obj_val 1.09637767541\n",
      "obj_val 1.09680177604\n",
      "obj_val 1.09600510641\n",
      "obj_val 1.09537040344\n",
      "obj_val 1.09474629497\n",
      "obj_val 1.09334827323\n",
      "obj_val 1.09107645782\n",
      "obj_val 1.0899331196\n",
      "obj_val 1.08753576548\n",
      "obj_val 1.08367616749\n",
      "obj_val 1.08266661049\n",
      "obj_val 1.0775064646\n",
      "\n",
      "Lambda = 0.50\n",
      "obj_val 1.36651216646\n",
      "obj_val 1.36651216646\n",
      "obj_val 2.39374677228\n",
      "obj_val 1.4293337528\n",
      "obj_val 1.27395617232\n",
      "obj_val 1.27324558476\n",
      "obj_val 1.27182694606\n",
      "obj_val 1.26650937022\n",
      "obj_val 1.25272082018\n",
      "obj_val 1.26120396488\n",
      "obj_val 1.24404626862\n",
      "obj_val 1.24115003912\n",
      "obj_val 1.23892631786\n",
      "obj_val 1.231891835\n",
      "obj_val 1.22424564238\n",
      "obj_val 1.22051556878\n",
      "obj_val 1.20260611775\n",
      "obj_val 1.20832408324\n",
      "obj_val 1.18793177318\n",
      "obj_val 1.18944330767\n",
      "obj_val 1.18590889894\n",
      "obj_val 1.20453164755\n",
      "obj_val 1.17955540248\n",
      "obj_val 1.17747097795\n",
      "obj_val 1.18650734645\n",
      "obj_val 1.17512313299\n",
      "obj_val 1.17220589137\n",
      "obj_val 1.16284007122\n",
      "obj_val 1.20935043804\n",
      "obj_val 1.16270497093\n",
      "obj_val 1.16213097763\n",
      "obj_val 1.16569442898\n",
      "obj_val 1.1595653378\n",
      "obj_val 1.15501999017\n",
      "obj_val 1.14952289405\n",
      "obj_val 1.16570228267\n",
      "obj_val 1.1471285951\n",
      "obj_val 1.14447166938\n",
      "obj_val 1.14202248666\n",
      "obj_val 1.14136559784\n",
      "obj_val 1.14068973967\n",
      "obj_val 1.13853904685\n",
      "obj_val 1.13789230704\n",
      "obj_val 1.14867253099\n",
      "obj_val 1.13741542763\n",
      "obj_val 1.13651145059\n",
      "obj_val 1.13448687355\n",
      "obj_val 1.14099373206\n",
      "obj_val 1.13375401668\n",
      "obj_val 1.13344809379\n",
      "obj_val 1.13331292165\n",
      "obj_val 1.13257707244\n",
      "obj_val 1.13213159048\n",
      "obj_val 1.13166955914\n",
      "obj_val 1.13139646888\n",
      "obj_val 1.13082024835\n",
      "obj_val 1.13035750268\n",
      "obj_val 1.12951958651\n",
      "obj_val 1.12829700177\n",
      "obj_val 1.1263319278\n",
      "obj_val 1.12431652006\n",
      "obj_val 1.12167153822\n",
      "obj_val 1.12971264657\n",
      "obj_val 1.12120099211\n",
      "obj_val 1.12083580071\n",
      "obj_val 1.12023043413\n",
      "obj_val 1.11976635299\n",
      "obj_val 1.11870117467\n",
      "obj_val 1.11833391263\n",
      "obj_val 1.11803242844\n",
      "obj_val 1.11875127112\n",
      "obj_val 1.11783483388\n",
      "obj_val 1.11779349186\n",
      "obj_val 1.11772287615\n",
      "obj_val 1.11750460556\n",
      "obj_val 1.11679137441\n",
      "obj_val 1.11614001654\n",
      "obj_val 1.11512590943\n",
      "obj_val 1.1142703721\n",
      "obj_val 1.11349711327\n",
      "obj_val 1.11323049866\n",
      "obj_val 1.11300704208\n",
      "obj_val 1.11242298722\n",
      "obj_val 1.11163100434\n",
      "obj_val 1.11049637719\n",
      "obj_val 1.11030643414\n",
      "obj_val 1.10976526071\n",
      "obj_val 1.10945860313\n",
      "obj_val 1.10913584763\n",
      "obj_val 1.10894601885\n",
      "obj_val 1.10922885429\n",
      "obj_val 1.10874568294\n",
      "\n",
      "Lambda = 0.60\n",
      "obj_val 1.36962561086\n",
      "obj_val 1.36962561086\n",
      "obj_val 2.39742489279\n",
      "obj_val 1.43245867992\n",
      "obj_val 1.27707073073\n",
      "obj_val 1.27637747839\n",
      "obj_val 1.27499306778\n",
      "obj_val 1.26979484612\n",
      "obj_val 1.25609089859\n",
      "obj_val 1.26381484927\n",
      "obj_val 1.24716832062\n",
      "obj_val 1.24255974866\n",
      "obj_val 1.24152681025\n",
      "obj_val 1.23426163527\n",
      "obj_val 1.22502399388\n",
      "obj_val 1.21718801634\n",
      "obj_val 1.195966209\n",
      "obj_val 1.18554352816\n",
      "obj_val 1.18173650753\n",
      "obj_val 1.18599942105\n",
      "obj_val 1.17392451654\n",
      "obj_val 1.1675465816\n",
      "obj_val 1.18628054463\n",
      "obj_val 1.16665891039\n",
      "obj_val 1.16511497472\n",
      "obj_val 1.16333169805\n",
      "obj_val 1.16426337301\n",
      "obj_val 1.16184024375\n",
      "obj_val 1.15998921976\n",
      "obj_val 1.15809844263\n",
      "obj_val 1.15645322493\n",
      "obj_val 1.15363630483\n",
      "obj_val 1.15127668601\n",
      "obj_val 1.14854365957\n",
      "obj_val 1.14773461847\n",
      "obj_val 1.14232661042\n",
      "obj_val 1.14199616744\n",
      "obj_val 1.13969628276\n",
      "obj_val 1.13747526786\n",
      "obj_val 1.13393225751\n",
      "obj_val 1.13255641139\n",
      "obj_val 1.12829808579\n",
      "obj_val 1.12613583064\n",
      "obj_val 1.12488428448\n",
      "obj_val 1.12311817775\n",
      "obj_val 1.12117986469\n",
      "obj_val 1.11947674724\n",
      "obj_val 1.11728222053\n",
      "obj_val 1.11465725508\n",
      "obj_val 1.12360120097\n",
      "obj_val 1.11407352249\n",
      "obj_val 1.1135235198\n",
      "obj_val 1.1125325503\n",
      "obj_val 1.11165882811\n",
      "obj_val 1.115135412\n",
      "obj_val 1.11125392601\n",
      "obj_val 1.11061662175\n",
      "obj_val 1.11041145108\n",
      "obj_val 1.10915311355\n",
      "obj_val 1.10876459463\n",
      "obj_val 1.10816081527\n",
      "obj_val 1.10772488366\n",
      "obj_val 1.10897145852\n",
      "obj_val 1.10739224823\n",
      "obj_val 1.10701133873\n",
      "obj_val 1.106420545\n",
      "obj_val 1.10617783016\n",
      "obj_val 1.10512347834\n",
      "obj_val 1.10421563377\n",
      "obj_val 1.10335235975\n",
      "obj_val 1.10204978942\n",
      "obj_val 1.10163874971\n",
      "obj_val 1.10215924745\n",
      "obj_val 1.10083917316\n",
      "obj_val 1.09992918298\n",
      "obj_val 1.09840600285\n",
      "obj_val 1.09753585533\n",
      "obj_val 1.0991646406\n",
      "obj_val 1.0967454804\n",
      "obj_val 1.09545796128\n",
      "obj_val 1.09475854307\n",
      "\n",
      "Lambda = 0.70\n",
      "obj_val 1.37273905526\n",
      "obj_val 1.37273905526\n",
      "obj_val 2.40109917055\n",
      "obj_val 1.43558283707\n",
      "obj_val 1.28018501918\n",
      "obj_val 1.27950712418\n",
      "obj_val 1.27815305174\n",
      "obj_val 1.27306102665\n",
      "obj_val 1.25944378236\n",
      "obj_val 1.26643617485\n",
      "obj_val 1.25028056813\n",
      "obj_val 1.24407318359\n",
      "obj_val 1.24923131382\n",
      "obj_val 1.24186374176\n",
      "obj_val 1.23790402459\n",
      "obj_val 1.23233442261\n",
      "obj_val 1.22235612142\n",
      "obj_val 1.21799899699\n",
      "obj_val 1.21430459814\n",
      "obj_val 1.20729772342\n",
      "obj_val 1.2030921461\n",
      "obj_val 1.20204778654\n",
      "obj_val 1.20034183255\n",
      "obj_val 1.19534188003\n",
      "obj_val 1.19383895618\n",
      "obj_val 1.19218240518\n",
      "obj_val 1.18939725764\n",
      "obj_val 1.18760650741\n",
      "obj_val 1.1833914639\n",
      "obj_val 1.17595175405\n",
      "obj_val 1.17085638699\n",
      "obj_val 1.16931587912\n",
      "obj_val 1.16342830615\n",
      "obj_val 1.15333824262\n",
      "obj_val 1.15981480113\n",
      "obj_val 1.1503398256\n",
      "obj_val 1.14613420652\n",
      "obj_val 1.15046140815\n",
      "obj_val 1.14499883449\n",
      "obj_val 1.14340881854\n",
      "obj_val 1.14233298247\n",
      "obj_val 1.14077425452\n",
      "obj_val 1.14027355588\n",
      "obj_val 1.13728267795\n",
      "obj_val 1.13680833552\n",
      "obj_val 1.13789779272\n",
      "obj_val 1.13565615029\n",
      "obj_val 1.13416418492\n",
      "obj_val 1.13379859485\n",
      "obj_val 1.13341496216\n",
      "obj_val 1.13269759122\n",
      "obj_val 1.13137035924\n",
      "obj_val 1.12859834255\n",
      "obj_val 1.14109623913\n",
      "obj_val 1.12784435736\n",
      "obj_val 1.12730785906\n",
      "obj_val 1.12698068553\n",
      "obj_val 1.12691278112\n",
      "obj_val 1.12620848803\n",
      "obj_val 1.12522730355\n",
      "obj_val 1.1239882944\n",
      "obj_val 1.12402614622\n",
      "obj_val 1.12336214649\n",
      "obj_val 1.12233952158\n",
      "obj_val 1.12186073056\n",
      "obj_val 1.1236571795\n",
      "obj_val 1.1213753968\n",
      "obj_val 1.12055399921\n",
      "obj_val 1.11975916749\n",
      "obj_val 1.12121930022\n",
      "obj_val 1.11920783113\n",
      "obj_val 1.11827949099\n",
      "obj_val 1.11773390331\n",
      "obj_val 1.11605995877\n",
      "obj_val 1.11375348848\n",
      "obj_val 1.11372008461\n",
      "obj_val 1.11252903329\n",
      "obj_val 1.11217924016\n",
      "obj_val 1.11182129186\n",
      "obj_val 1.11088903056\n",
      "obj_val 1.10952875278\n",
      "obj_val 1.1092164801\n",
      "obj_val 1.10876802635\n",
      "obj_val 1.10827420825\n",
      "obj_val 1.10702282689\n",
      "obj_val 1.10517360662\n",
      "obj_val 1.10471177836\n",
      "\n",
      "Lambda = 0.80\n",
      "obj_val 1.37585249965\n",
      "obj_val 1.37585249965\n",
      "obj_val 2.40476960732\n",
      "obj_val 1.43870622458\n",
      "obj_val 1.2832990377\n",
      "obj_val 1.28263452233\n",
      "obj_val 1.28130689299\n",
      "obj_val 1.27630774184\n",
      "obj_val 1.26277494936\n",
      "obj_val 1.26907808773\n",
      "obj_val 1.25339230467\n",
      "obj_val 1.24601354953\n",
      "obj_val 1.2469179912\n",
      "obj_val 1.2423662931\n",
      "obj_val 1.23629659896\n",
      "obj_val 1.23072913251\n",
      "obj_val 1.21861139143\n",
      "obj_val 1.21941519982\n",
      "obj_val 1.21271919897\n",
      "obj_val 1.20416989158\n",
      "obj_val 1.20501497009\n",
      "obj_val 1.20040449112\n",
      "obj_val 1.19823272269\n",
      "obj_val 1.1976169333\n",
      "obj_val 1.19348474369\n",
      "obj_val 1.19208852108\n",
      "obj_val 1.18337688313\n",
      "obj_val 1.17787817831\n",
      "obj_val 1.17024434428\n",
      "obj_val 1.16713102795\n",
      "obj_val 1.15804635742\n",
      "obj_val 1.15692476434\n",
      "obj_val 1.15478878725\n",
      "obj_val 1.14983918716\n",
      "obj_val 1.1385542552\n",
      "obj_val 1.13614787581\n",
      "obj_val 1.12956286412\n",
      "obj_val 1.1362785146\n",
      "obj_val 1.12733081187\n",
      "obj_val 1.12353739382\n",
      "obj_val 1.12005688454\n",
      "obj_val 1.11917065245\n",
      "obj_val 1.11614825328\n",
      "obj_val 1.11520584139\n",
      "obj_val 1.11398597329\n",
      "obj_val 1.11345585675\n",
      "obj_val 1.11268029402\n",
      "obj_val 1.11068131884\n",
      "obj_val 1.11021602096\n",
      "obj_val 1.10957385101\n",
      "obj_val 1.10870404283\n",
      "obj_val 1.10804215272\n",
      "obj_val 1.10770703656\n",
      "obj_val 1.10599943556\n",
      "obj_val 1.10452470541\n",
      "obj_val 1.10688584606\n",
      "obj_val 1.10336079564\n",
      "obj_val 1.10130679744\n",
      "obj_val 1.10024852463\n",
      "obj_val 1.1045871383\n",
      "obj_val 1.09928446312\n",
      "obj_val 1.0976029898\n",
      "obj_val 1.0960614808\n",
      "obj_val 1.12597824201\n",
      "obj_val 1.0957791621\n",
      "obj_val 1.09526589244\n",
      "obj_val 1.09449498149\n",
      "obj_val 1.09615866342\n",
      "obj_val 1.09408630323\n",
      "obj_val 1.09340718648\n",
      "obj_val 1.09287844605\n",
      "obj_val 1.09269369728\n",
      "obj_val 1.09223194652\n",
      "obj_val 1.0911344081\n",
      "obj_val 1.0902083971\n",
      "obj_val 1.08776698488\n",
      "obj_val 1.08933188799\n",
      "obj_val 1.08683146305\n",
      "obj_val 1.08566745002\n",
      "obj_val 1.08700100421\n",
      "obj_val 1.08528305339\n",
      "obj_val 1.08475920628\n",
      "obj_val 1.08457333918\n",
      "obj_val 1.084440174\n",
      "obj_val 1.0842355285\n",
      "obj_val 1.0841132314\n",
      "obj_val 1.08408521052\n",
      "obj_val 1.08385009191\n",
      "obj_val 1.08374726948\n",
      "obj_val 1.08349498369\n",
      "obj_val 1.08316100568\n",
      "\n",
      "Lambda = 0.90\n",
      "obj_val 1.37896594405\n",
      "obj_val 1.37896594405\n",
      "obj_val 2.40843620491\n",
      "obj_val 1.44182884277\n",
      "obj_val 1.28641278635\n",
      "obj_val 1.28575967312\n",
      "obj_val 1.28445458749\n",
      "obj_val 1.27953484553\n",
      "obj_val 1.2660804849\n",
      "obj_val 1.27175493585\n",
      "obj_val 1.25650835753\n",
      "obj_val 1.24839676444\n",
      "obj_val 1.24586400894\n",
      "obj_val 1.24065671627\n",
      "obj_val 1.22870835551\n",
      "obj_val 1.22288408541\n",
      "obj_val 1.211139844\n",
      "obj_val 1.21284077274\n",
      "obj_val 1.20488076457\n",
      "obj_val 1.19880854797\n",
      "obj_val 1.19767642243\n",
      "obj_val 1.19511607331\n",
      "obj_val 1.19454375206\n",
      "obj_val 1.18956726845\n",
      "obj_val 1.23005675255\n",
      "obj_val 1.18397076356\n",
      "obj_val 1.21542148398\n",
      "obj_val 1.18393364105\n",
      "obj_val 1.18337167377\n",
      "obj_val 1.18218112389\n",
      "obj_val 1.17795232937\n",
      "obj_val 1.17405625116\n",
      "obj_val 1.17225591754\n",
      "obj_val 1.19516360881\n",
      "obj_val 1.17227412306\n",
      "obj_val 1.17142855871\n",
      "obj_val 1.17064849657\n",
      "obj_val 1.16916432259\n",
      "obj_val 1.16626315756\n",
      "obj_val 1.1711085067\n",
      "obj_val 1.16535238097\n",
      "obj_val 1.16494727327\n",
      "obj_val 1.16474757428\n",
      "obj_val 1.16360482685\n",
      "obj_val 1.16156069274\n",
      "obj_val 1.16255390015\n",
      "obj_val 1.1601108199\n",
      "obj_val 1.15839672372\n",
      "obj_val 1.15779219626\n",
      "obj_val 1.15738201419\n",
      "obj_val 1.15631972307\n",
      "obj_val 1.15512857623\n",
      "obj_val 1.15521978889\n",
      "obj_val 1.15458183533\n",
      "obj_val 1.15378293746\n",
      "obj_val 1.15352263869\n",
      "obj_val 1.15512075595\n",
      "obj_val 1.15320108916\n",
      "obj_val 1.15286637548\n",
      "obj_val 1.1522451402\n",
      "obj_val 1.15075441077\n",
      "obj_val 1.14824219665\n",
      "obj_val 1.14626159352\n",
      "obj_val 1.14311911857\n",
      "obj_val 1.14108163116\n",
      "obj_val 1.13284057573\n",
      "obj_val 1.12997000143\n",
      "obj_val 1.18644712101\n",
      "obj_val 1.12799998455\n",
      "obj_val 1.12748669745\n",
      "obj_val 1.12591312453\n",
      "obj_val 1.1255090338\n",
      "obj_val 1.12283032426\n",
      "obj_val 1.12294843902\n",
      "obj_val 1.12173632914\n",
      "obj_val 1.12090771283\n",
      "obj_val 1.11958193015\n",
      "obj_val 1.11882430585\n",
      "obj_val 1.11673754152\n",
      "obj_val 1.11448752024\n",
      "obj_val 1.11726582168\n",
      "obj_val 1.11375225153\n",
      "obj_val 1.11329292829\n",
      "obj_val 1.11320372092\n",
      "obj_val 1.11268269383\n",
      "obj_val 1.11225528249\n",
      "obj_val 1.11169720151\n",
      "obj_val 1.11149309065\n",
      "obj_val 1.11135220433\n",
      "obj_val 1.11085624485\n",
      "obj_val 1.11074859652\n",
      "obj_val 1.11094330796\n",
      "obj_val 1.11051704411\n",
      "\n",
      "Lambda = 1.00\n",
      "obj_val 1.38207938845\n",
      "obj_val 1.38207938845\n",
      "obj_val 2.41209896508\n",
      "obj_val 1.44495069195\n",
      "obj_val 1.28952626517\n",
      "obj_val 1.28888257692\n",
      "obj_val 1.28759613209\n",
      "obj_val 1.28274221505\n",
      "obj_val 1.26935708012\n",
      "obj_val 1.27448160626\n",
      "obj_val 1.25962875155\n",
      "obj_val 1.2510676802\n",
      "obj_val 1.24675675646\n",
      "obj_val 1.23824186691\n",
      "obj_val 1.22295265566\n",
      "obj_val 1.20931614037\n",
      "obj_val 1.19737982056\n",
      "obj_val 1.18132665397\n",
      "obj_val 1.1726130816\n",
      "obj_val 1.17042336268\n",
      "obj_val 1.18384305512\n",
      "obj_val 1.16624556015\n",
      "obj_val 1.16379355934\n",
      "obj_val 1.16288509631\n",
      "obj_val 1.16092310581\n",
      "obj_val 1.15948263341\n",
      "obj_val 1.15687430516\n",
      "obj_val 1.15758224408\n",
      "obj_val 1.15511514611\n",
      "obj_val 1.16142414191\n",
      "obj_val 1.15392338534\n",
      "obj_val 1.15235421494\n",
      "obj_val 1.15049709101\n",
      "obj_val 1.14913080325\n",
      "obj_val 1.14813179516\n",
      "obj_val 1.14649191568\n",
      "obj_val 1.14571130535\n",
      "obj_val 1.145860349\n",
      "obj_val 1.14462386948\n",
      "obj_val 1.14264339733\n",
      "obj_val 1.1419122526\n",
      "obj_val 1.14055343\n",
      "obj_val 1.13704345414\n",
      "obj_val 1.14044038987\n",
      "obj_val 1.13594409019\n",
      "obj_val 1.13420945493\n",
      "obj_val 1.13357230514\n",
      "obj_val 1.13033998814\n",
      "obj_val 1.1310001617\n",
      "obj_val 1.12885536512\n",
      "obj_val 1.1281049116\n",
      "obj_val 1.12784389835\n",
      "obj_val 1.12621530116\n",
      "obj_val 1.12547113983\n",
      "obj_val 1.12572658608\n",
      "obj_val 1.12441551352\n",
      "obj_val 1.12445909965\n",
      "obj_val 1.12386038634\n",
      "obj_val 1.12319837403\n",
      "obj_val 1.12232526484\n",
      "obj_val 1.12364584469\n",
      "obj_val 1.12206568441\n",
      "obj_val 1.12158707784\n",
      "obj_val 1.12058934287\n",
      "obj_val 1.12080415738\n",
      "obj_val 1.11992003838\n",
      "obj_val 1.11875381367\n",
      "obj_val 1.11787619734\n",
      "obj_val 1.11623896328\n",
      "obj_val 1.11429161537\n",
      "obj_val 1.11552639336\n",
      "obj_val 1.11353888675\n",
      "obj_val 1.1132192991\n",
      "obj_val 1.11306788846\n",
      "obj_val 1.1124637129\n",
      "obj_val 1.11199939004\n",
      "obj_val 1.11175975429\n",
      "obj_val 1.1116831489\n",
      "obj_val 1.1111538034\n",
      "obj_val 1.11070652101\n",
      "obj_val 1.1116403781\n",
      "obj_val 1.11035278459\n",
      "obj_val 1.10980442409\n",
      "obj_val 1.10961215032\n",
      "obj_val 1.10876317066\n",
      "\n",
      "n_hidden = 10\n",
      "obj_val 1.68542881879\n",
      "obj_val 1.68542881879\n",
      "obj_val 1.28173444816\n",
      "obj_val 1.27761096175\n",
      "obj_val 1.27692893821\n",
      "obj_val 1.27678011287\n",
      "obj_val 1.27665452416\n",
      "obj_val 1.27615884343\n",
      "obj_val 1.27425876363\n",
      "obj_val 1.27100981763\n",
      "obj_val 1.27665452416\n",
      "obj_val 1.276529642\n",
      "obj_val 1.27628183469\n",
      "obj_val 1.27579322067\n",
      "obj_val 1.2748401355\n",
      "obj_val 1.27299864416\n",
      "obj_val 1.26973627487\n",
      "obj_val 1.26954174094\n",
      "obj_val 1.26932992067\n",
      "obj_val 1.26910177152\n",
      "obj_val 1.26827942726\n",
      "obj_val 1.26636147458\n",
      "obj_val 1.26348962909\n",
      "obj_val 1.2587104846\n",
      "obj_val 1.25840482005\n",
      "obj_val 1.25839070625\n",
      "obj_val 1.25776522067\n",
      "obj_val 1.25394861976\n",
      "obj_val 1.25962910801\n",
      "obj_val 1.25748257615\n",
      "obj_val 1.25386884332\n",
      "obj_val 1.25981885462\n",
      "obj_val 1.25610152567\n",
      "obj_val 1.25376798705\n",
      "obj_val 1.25358057006\n",
      "obj_val 1.25321729943\n",
      "obj_val 1.25207541886\n",
      "obj_val 1.24719147411\n",
      "obj_val 1.2302332697\n",
      "obj_val 1.2159728874\n",
      "obj_val 1.38638770074\n",
      "obj_val 1.21176376123\n",
      "obj_val 1.20391289452\n",
      "obj_val 1.19264772645\n",
      "obj_val 1.19065093025\n",
      "obj_val 1.18841542861\n",
      "obj_val 1.26907576156\n",
      "obj_val 1.18411742439\n",
      "obj_val 1.18062516879\n",
      "obj_val 1.2361497007\n",
      "obj_val 1.17973144944\n",
      "obj_val 1.17929497572\n",
      "obj_val 1.19831803464\n",
      "obj_val 1.17723719938\n",
      "obj_val 1.17343795185\n",
      "obj_val 1.16757119122\n",
      "obj_val 1.17011950354\n",
      "obj_val 1.16397670918\n",
      "obj_val 1.1577594777\n",
      "obj_val 1.15435186359\n",
      "obj_val 1.14358240105\n",
      "obj_val 1.13733402123\n",
      "obj_val 1.13491341755\n",
      "obj_val 1.13944201627\n",
      "obj_val 1.13250516522\n",
      "obj_val 1.13122046265\n",
      "obj_val 1.13084789807\n",
      "obj_val 1.12874113899\n",
      "obj_val 1.13218288953\n",
      "obj_val 1.12814968603\n",
      "obj_val 1.12765905796\n",
      "obj_val 1.12673538506\n",
      "obj_val 1.12397943177\n",
      "obj_val 1.12542679073\n",
      "obj_val 1.12318146191\n",
      "obj_val 1.11927781072\n",
      "obj_val 1.13667928131\n",
      "obj_val 1.11947187475\n",
      "obj_val 1.11917378425\n",
      "obj_val 1.11899627527\n",
      "obj_val 1.11883934755\n",
      "obj_val 1.11827308939\n",
      "obj_val 1.11777435639\n",
      "obj_val 1.1162009022\n",
      "obj_val 1.12390422063\n",
      "obj_val 1.11575165862\n",
      "obj_val 1.11627808664\n",
      "obj_val 1.11471087113\n",
      "obj_val 1.11922658431\n",
      "obj_val 1.114537095\n",
      "obj_val 1.1142625289\n",
      "obj_val 1.11415213801\n",
      "obj_val 1.11341515366\n",
      "obj_val 1.11113822407\n",
      "obj_val 1.10780431\n",
      "obj_val 1.12204626064\n",
      "obj_val 1.10653865316\n",
      "obj_val 1.10572037087\n",
      "obj_val 1.10531030374\n",
      "obj_val 1.10518621554\n",
      "obj_val 1.10423658938\n",
      "obj_val 1.10298154556\n",
      "obj_val 1.10152665172\n",
      "obj_val 1.09937097217\n",
      "obj_val 1.09894836597\n",
      "obj_val 1.09575560987\n",
      "obj_val 1.10245767334\n",
      "obj_val 1.09501076992\n",
      "obj_val 1.09954232718\n",
      "obj_val 1.09492784839\n",
      "obj_val 1.09477802516\n",
      "obj_val 1.09453331839\n",
      "obj_val 1.09388325792\n",
      "obj_val 1.09343511291\n",
      "obj_val 1.09746674437\n",
      "obj_val 1.09328500793\n",
      "obj_val 1.0930277982\n",
      "obj_val 1.09279122004\n",
      "obj_val 1.09232900619\n",
      "\n",
      "n_hidden = 20\n",
      "obj_val 1.76159623569\n",
      "obj_val 1.76159623569\n",
      "obj_val 2.28964358182\n",
      "obj_val 1.29804741342\n",
      "obj_val 1.3299802488\n",
      "obj_val 1.28754932224\n",
      "obj_val 1.28178419174\n",
      "obj_val 1.27228984513\n",
      "obj_val 1.27087092444\n",
      "obj_val 1.26946639804\n",
      "obj_val 1.27698488793\n",
      "obj_val 1.26773035711\n",
      "obj_val 1.26449358436\n",
      "obj_val 1.25571158638\n",
      "obj_val 1.27574559315\n",
      "obj_val 1.25453631645\n",
      "obj_val 1.25434982267\n",
      "obj_val 1.25181272641\n",
      "obj_val 1.24865832454\n",
      "obj_val 1.2480434773\n",
      "obj_val 1.24527199715\n",
      "obj_val 1.23919288795\n",
      "obj_val 1.22883109996\n",
      "obj_val 1.20603877893\n",
      "obj_val 1.19867016264\n",
      "obj_val 1.18881414849\n",
      "obj_val 1.1920934261\n",
      "obj_val 1.18451814485\n",
      "obj_val 1.1761644642\n",
      "obj_val 1.16530779601\n",
      "obj_val 1.16305780331\n",
      "obj_val 1.18311291535\n",
      "obj_val 1.15970112635\n",
      "obj_val 1.15353340925\n",
      "obj_val 1.17105918654\n",
      "obj_val 1.15260673074\n",
      "obj_val 1.14691600069\n",
      "obj_val 1.14354516378\n",
      "obj_val 1.14282747419\n",
      "obj_val 1.14188998825\n",
      "obj_val 1.13543533264\n",
      "obj_val 1.15292346418\n",
      "obj_val 1.13474304873\n",
      "obj_val 1.13362402016\n",
      "obj_val 1.13291804736\n",
      "obj_val 1.13012818198\n",
      "obj_val 1.12978763239\n",
      "obj_val 1.13113137347\n",
      "obj_val 1.12836963533\n",
      "obj_val 1.12721691151\n",
      "obj_val 1.1259396063\n",
      "obj_val 1.12933234115\n",
      "obj_val 1.12561233322\n",
      "obj_val 1.12502590622\n",
      "obj_val 1.12450266225\n",
      "obj_val 1.12657299523\n",
      "obj_val 1.12419896907\n",
      "obj_val 1.12361780667\n",
      "obj_val 1.1219061072\n",
      "obj_val 1.11972707199\n",
      "obj_val 1.13124259747\n",
      "obj_val 1.11888108924\n",
      "obj_val 1.11757238487\n",
      "obj_val 1.11727637013\n",
      "obj_val 1.12006443118\n",
      "obj_val 1.11693467133\n",
      "obj_val 1.1162761284\n",
      "obj_val 1.11428292488\n",
      "obj_val 1.11283982809\n",
      "obj_val 1.11440645079\n",
      "obj_val 1.11142548379\n",
      "obj_val 1.10930733535\n",
      "obj_val 1.11004921193\n",
      "obj_val 1.10832751021\n",
      "obj_val 1.1063802772\n",
      "obj_val 1.10680381697\n",
      "obj_val 1.10432208916\n",
      "obj_val 1.11733014739\n",
      "obj_val 1.1036339509\n",
      "obj_val 1.10252346024\n",
      "obj_val 1.10184419241\n",
      "obj_val 1.10371719723\n",
      "obj_val 1.10121448513\n",
      "obj_val 1.09999703819\n",
      "obj_val 1.09637760923\n",
      "obj_val 1.09490106115\n",
      "obj_val 1.12558124508\n",
      "obj_val 1.09424582855\n",
      "obj_val 1.09322028302\n",
      "obj_val 1.092900316\n",
      "obj_val 1.09234329486\n",
      "obj_val 1.09202380498\n",
      "obj_val 1.09105088629\n",
      "obj_val 1.09027079321\n",
      "obj_val 1.08998714825\n",
      "obj_val 1.08980343476\n",
      "obj_val 1.08911373103\n",
      "obj_val 1.08896092904\n",
      "obj_val 1.08843175023\n",
      "obj_val 1.0883272959\n",
      "obj_val 1.08823078499\n",
      "obj_val 1.08797940916\n",
      "\n",
      "n_hidden = 30\n",
      "obj_val 1.90832128999\n",
      "obj_val 1.90832128999\n",
      "obj_val 3.01018773911\n",
      "obj_val 1.33098263598\n",
      "obj_val 1.28961994453\n",
      "obj_val 1.3167819481\n",
      "obj_val 1.28229384569\n",
      "obj_val 1.28322822939\n",
      "obj_val 1.28193690833\n",
      "obj_val 1.2816935611\n",
      "obj_val 1.28164838746\n",
      "obj_val 1.28137381506\n",
      "obj_val 1.28105708117\n",
      "obj_val 1.28083831852\n",
      "obj_val 1.28053119343\n",
      "obj_val 1.28015145748\n",
      "obj_val 1.27986209482\n",
      "obj_val 1.28029502279\n",
      "obj_val 1.27975254779\n",
      "obj_val 1.27955923851\n",
      "obj_val 1.27937600054\n",
      "obj_val 1.27918825035\n",
      "obj_val 1.27912324439\n",
      "obj_val 1.27895664245\n",
      "obj_val 1.27871722511\n",
      "obj_val 1.27866572903\n",
      "obj_val 1.27819155582\n",
      "obj_val 1.27798716354\n",
      "obj_val 1.27716560235\n",
      "obj_val 1.2764543436\n",
      "obj_val 1.2756935655\n",
      "obj_val 1.27449533073\n",
      "obj_val 1.2683871103\n",
      "obj_val 1.29413827284\n",
      "obj_val 1.25101612927\n",
      "obj_val 1.25010254652\n",
      "obj_val 1.26804562884\n",
      "obj_val 1.24662090976\n",
      "obj_val 1.24028821135\n",
      "obj_val 1.214231072\n",
      "obj_val 1.19740805194\n",
      "obj_val 1.32927433755\n",
      "obj_val 1.19718525003\n",
      "obj_val 1.19427291638\n",
      "obj_val 1.18806947638\n",
      "obj_val 1.16947206954\n",
      "obj_val 1.1750973887\n",
      "obj_val 1.16052411731\n",
      "obj_val 1.24851985557\n",
      "obj_val 1.15809400741\n",
      "obj_val 1.15485678972\n",
      "obj_val 1.16996706597\n",
      "obj_val 1.15391908873\n",
      "obj_val 1.19552959474\n",
      "obj_val 1.15346431615\n",
      "obj_val 1.15290063164\n",
      "obj_val 1.15280396019\n",
      "obj_val 1.15087527124\n",
      "obj_val 1.15104585011\n",
      "obj_val 1.15004457839\n",
      "obj_val 1.14749492007\n",
      "obj_val 1.15011489425\n",
      "obj_val 1.14700935998\n",
      "obj_val 1.14612248395\n",
      "obj_val 1.14473887608\n",
      "obj_val 1.1671883353\n",
      "obj_val 1.144498618\n",
      "obj_val 1.14408869668\n",
      "obj_val 1.14370497942\n",
      "obj_val 1.14324759154\n",
      "obj_val 1.14314959816\n",
      "obj_val 1.14262040514\n",
      "obj_val 1.1419084788\n",
      "obj_val 1.14275465735\n",
      "obj_val 1.14171201863\n",
      "obj_val 1.14135061844\n",
      "obj_val 1.14072415145\n",
      "obj_val 1.1389802707\n",
      "obj_val 1.13948643183\n",
      "obj_val 1.13832467436\n",
      "obj_val 1.1385300337\n",
      "obj_val 1.13723259583\n",
      "obj_val 1.13517700198\n",
      "obj_val 1.13287034446\n",
      "obj_val 1.12843981825\n",
      "obj_val 1.27875085464\n",
      "obj_val 1.12802157229\n",
      "obj_val 1.14870954995\n",
      "obj_val 1.1266092216\n",
      "obj_val 1.12566695806\n",
      "obj_val 1.1255136591\n",
      "obj_val 1.12473857875\n",
      "obj_val 1.12359852937\n",
      "obj_val 1.1232111872\n",
      "obj_val 1.12356841971\n",
      "obj_val 1.12244247984\n",
      "obj_val 1.12102937577\n",
      "obj_val 1.12107243162\n",
      "obj_val 1.12012387813\n",
      "obj_val 1.12943979441\n",
      "obj_val 1.11986956755\n",
      "\n",
      "n_hidden = 40\n",
      "obj_val 1.30120820001\n",
      "obj_val 1.30120820001\n",
      "obj_val 2.19609697628\n",
      "obj_val 1.31260780214\n",
      "obj_val 1.2769027965\n",
      "obj_val 1.27911980878\n",
      "obj_val 1.2684045127\n",
      "obj_val 1.26956037677\n",
      "obj_val 1.26393546669\n",
      "obj_val 1.26588216581\n",
      "obj_val 1.26256178034\n",
      "obj_val 1.26059384664\n",
      "obj_val 1.2578102085\n",
      "obj_val 1.2584914103\n",
      "obj_val 1.25656528752\n",
      "obj_val 1.25504435219\n",
      "obj_val 1.25300966876\n",
      "obj_val 1.25298607124\n",
      "obj_val 1.25184026182\n",
      "obj_val 1.24961638124\n",
      "obj_val 1.24425185693\n",
      "obj_val 1.24005291235\n",
      "obj_val 1.23220636495\n",
      "obj_val 1.21970494464\n",
      "obj_val 1.20505740624\n",
      "obj_val 1.20273130075\n",
      "obj_val 1.18640271433\n",
      "obj_val 1.29097277062\n",
      "obj_val 1.18664990752\n",
      "obj_val 1.18118327152\n",
      "obj_val 1.18855705328\n",
      "obj_val 1.17397038917\n",
      "obj_val 1.16445027296\n",
      "obj_val 1.16388185599\n",
      "obj_val 1.15950466064\n",
      "obj_val 1.15385196206\n",
      "obj_val 1.16386008795\n",
      "obj_val 1.1523667931\n",
      "obj_val 1.15345069874\n",
      "obj_val 1.15181538046\n",
      "obj_val 1.15077086336\n",
      "obj_val 1.14834983286\n",
      "obj_val 1.14609194255\n",
      "obj_val 1.14562938634\n",
      "obj_val 1.14135798479\n",
      "obj_val 1.13981849839\n",
      "obj_val 1.14358755797\n",
      "obj_val 1.13789918222\n",
      "obj_val 1.13484283533\n",
      "obj_val 1.13379449423\n",
      "obj_val 1.12990311002\n",
      "obj_val 1.15504879266\n",
      "obj_val 1.12952085971\n",
      "obj_val 1.12928726737\n",
      "obj_val 1.12820718191\n",
      "obj_val 1.12682009416\n",
      "obj_val 1.12386158764\n",
      "obj_val 1.12991036936\n",
      "obj_val 1.12309434985\n",
      "obj_val 1.12225200946\n",
      "obj_val 1.12087040384\n",
      "obj_val 1.12030061152\n",
      "obj_val 1.12031146091\n",
      "obj_val 1.1194058611\n",
      "obj_val 1.11783861417\n",
      "obj_val 1.1162332789\n",
      "obj_val 1.12499590086\n",
      "obj_val 1.11554600078\n",
      "obj_val 1.11477736375\n",
      "obj_val 1.11378455856\n",
      "obj_val 1.1123171179\n",
      "obj_val 1.11191346433\n",
      "obj_val 1.10827768267\n",
      "obj_val 1.13943676008\n",
      "obj_val 1.10787547152\n",
      "obj_val 1.12913992197\n",
      "obj_val 1.1074732288\n",
      "obj_val 1.10688927626\n",
      "obj_val 1.10675810901\n",
      "obj_val 1.1058328868\n",
      "obj_val 1.1056001889\n",
      "obj_val 1.10529589324\n",
      "obj_val 1.1045831901\n",
      "obj_val 1.10438318043\n",
      "obj_val 1.10416898171\n",
      "obj_val 1.10354376815\n",
      "obj_val 1.10335349886\n",
      "obj_val 1.10252692353\n",
      "obj_val 1.10120973447\n",
      "obj_val 1.10051928618\n",
      "obj_val 1.10068725975\n",
      "obj_val 1.0995605302\n",
      "\n",
      "n_hidden = 50\n",
      "obj_val 1.40228334396\n",
      "obj_val 1.40228334396\n",
      "obj_val 2.9398461663\n",
      "obj_val 1.41039082919\n",
      "obj_val 1.27953372592\n",
      "obj_val 1.29534803553\n",
      "obj_val 1.28547590828\n",
      "obj_val 1.26954304134\n",
      "obj_val 1.25794360797\n",
      "obj_val 1.24858328779\n",
      "obj_val 1.24488649723\n",
      "obj_val 1.23867186946\n",
      "obj_val 1.23384277148\n",
      "obj_val 1.22960733316\n",
      "obj_val 1.23813153405\n",
      "obj_val 1.22793568614\n",
      "obj_val 1.22731983311\n",
      "obj_val 1.22252848769\n",
      "obj_val 1.22081647522\n",
      "obj_val 1.21774952669\n",
      "obj_val 1.2136393704\n",
      "obj_val 1.21179950674\n",
      "obj_val 1.20257277953\n",
      "obj_val 1.19961058335\n",
      "obj_val 1.19075032287\n",
      "obj_val 1.18993514621\n",
      "obj_val 1.185569851\n",
      "obj_val 1.18246212615\n",
      "obj_val 1.17955936602\n",
      "obj_val 1.176266665\n",
      "obj_val 1.17595950337\n",
      "obj_val 1.17455436199\n",
      "obj_val 1.17149663555\n",
      "obj_val 1.16800568759\n",
      "obj_val 1.16653351276\n",
      "obj_val 1.16462935287\n",
      "obj_val 1.16160997569\n",
      "obj_val 1.1582929352\n",
      "obj_val 1.15595416987\n",
      "obj_val 1.15873148299\n",
      "obj_val 1.15516826579\n",
      "obj_val 1.15380216716\n",
      "obj_val 1.15246679408\n",
      "obj_val 1.15656175318\n",
      "obj_val 1.15167900979\n",
      "obj_val 1.1505076597\n",
      "obj_val 1.15023211441\n",
      "obj_val 1.14818189475\n",
      "obj_val 1.14694203813\n",
      "obj_val 1.14666386263\n",
      "obj_val 1.14519409941\n",
      "obj_val 1.14282193416\n",
      "obj_val 1.14155402239\n",
      "obj_val 1.13888897228\n",
      "obj_val 1.13854094443\n",
      "obj_val 1.13539309222\n",
      "obj_val 1.1341878245\n",
      "obj_val 1.13359111791\n",
      "obj_val 1.13184116175\n",
      "obj_val 1.12958773907\n",
      "obj_val 1.12849766021\n",
      "obj_val 1.12813553647\n",
      "obj_val 1.12808516204\n",
      "obj_val 1.12736266372\n",
      "obj_val 1.12645896563\n",
      "obj_val 1.1254729957\n",
      "obj_val 1.12444562759\n",
      "obj_val 1.1228212287\n",
      "obj_val 1.12203897887\n",
      "obj_val 1.11889551291\n",
      "obj_val 1.13683427673\n",
      "obj_val 1.11851156583\n",
      "obj_val 1.11814874851\n",
      "obj_val 1.11771690253\n",
      "obj_val 1.11725297823\n",
      "obj_val 1.11659309341\n",
      "obj_val 1.11646141374\n",
      "obj_val 1.11543815568\n",
      "obj_val 1.11464063493\n",
      "obj_val 1.11493680765\n",
      "obj_val 1.11430914878\n",
      "\n",
      "n_hidden = 60\n",
      "obj_val 1.36955721622\n",
      "obj_val 1.36955721622\n",
      "obj_val 1.99098138181\n",
      "obj_val 1.30024515141\n",
      "obj_val 1.29432136819\n",
      "obj_val 1.28561920514\n",
      "obj_val 1.28289470107\n",
      "obj_val 1.27800183015\n",
      "obj_val 1.27700928091\n",
      "obj_val 1.27527825546\n",
      "obj_val 1.27615881103\n",
      "obj_val 1.27299098773\n",
      "obj_val 1.27290167914\n",
      "obj_val 1.2736756511\n",
      "obj_val 1.27147613768\n",
      "obj_val 1.26934885565\n",
      "obj_val 1.26881600094\n",
      "obj_val 1.26492688788\n",
      "obj_val 1.25958990017\n",
      "obj_val 1.28205271454\n",
      "obj_val 1.25830353789\n",
      "obj_val 1.25041467305\n",
      "obj_val 1.33247588685\n",
      "obj_val 1.25019103815\n",
      "obj_val 1.24949891816\n",
      "obj_val 1.25548662574\n",
      "obj_val 1.24721634126\n",
      "obj_val 1.24328272082\n",
      "obj_val 1.23995624864\n",
      "obj_val 1.23433356091\n",
      "obj_val 1.22794827702\n",
      "obj_val 1.23086436618\n",
      "obj_val 1.22558185668\n",
      "obj_val 1.22219928951\n",
      "obj_val 1.22599404616\n",
      "obj_val 1.21962794053\n",
      "obj_val 1.20854803632\n",
      "obj_val 1.20570852658\n",
      "obj_val 1.2206897953\n",
      "obj_val 1.2021743718\n",
      "obj_val 1.19999744616\n",
      "obj_val 1.19587430651\n",
      "obj_val 1.2159091476\n",
      "obj_val 1.19448469339\n",
      "obj_val 1.18803475688\n",
      "obj_val 1.19060139842\n",
      "obj_val 1.18513731874\n",
      "obj_val 1.18245237584\n",
      "obj_val 1.18043369868\n",
      "obj_val 1.17853786367\n",
      "obj_val 1.17528626116\n",
      "obj_val 1.17157229948\n",
      "obj_val 1.20519837564\n",
      "obj_val 1.17051522329\n",
      "obj_val 1.16868868561\n",
      "obj_val 1.16710738656\n",
      "obj_val 1.16567766126\n",
      "obj_val 1.16367718719\n",
      "obj_val 1.16832240556\n",
      "obj_val 1.16296060032\n",
      "obj_val 1.16178523452\n",
      "obj_val 1.16125977939\n",
      "obj_val 1.16103582388\n",
      "obj_val 1.16063191253\n",
      "obj_val 1.16013555027\n",
      "obj_val 1.1586490446\n",
      "obj_val 1.15771582927\n",
      "obj_val 1.15772795425\n",
      "obj_val 1.15646974004\n",
      "obj_val 1.1556628303\n",
      "obj_val 1.15471061968\n",
      "obj_val 1.15316528645\n",
      "obj_val 1.1520609623\n",
      "obj_val 1.15022477227\n",
      "obj_val 1.14825140358\n",
      "obj_val 1.14588676613\n",
      "obj_val 1.15126500936\n",
      "obj_val 1.14531363749\n",
      "obj_val 1.14488312866\n",
      "obj_val 1.14426985564\n",
      "obj_val 1.14322351509\n",
      "obj_val 1.14242170841\n",
      "obj_val 1.14198271131\n",
      "obj_val 1.14140680337\n",
      "obj_val 1.14015703274\n",
      "obj_val 1.13962366233\n",
      "obj_val 1.13934822008\n",
      "obj_val 1.13873642276\n",
      "\n",
      "n_hidden = 70\n",
      "obj_val 1.6800167255\n",
      "obj_val 1.6800167255\n",
      "obj_val 5.21035403091\n",
      "obj_val 1.97301414212\n",
      "obj_val 1.30947436389\n",
      "obj_val 1.78787161292\n",
      "obj_val 1.25290272946\n",
      "obj_val 1.42231096458\n",
      "obj_val 1.24256497429\n",
      "obj_val 1.2417159183\n",
      "obj_val 1.23906071803\n",
      "obj_val 1.23397543617\n",
      "obj_val 1.22644865401\n",
      "obj_val 1.21924122465\n",
      "obj_val 1.20947306906\n",
      "obj_val 1.20612850171\n",
      "obj_val 1.20333705605\n",
      "obj_val 1.19641415119\n",
      "obj_val 1.18748316927\n",
      "obj_val 1.18134496292\n",
      "obj_val 1.17636476069\n",
      "obj_val 1.17561636974\n",
      "obj_val 1.17073630846\n",
      "obj_val 1.1679859222\n",
      "obj_val 1.1670661722\n",
      "obj_val 1.16338743091\n",
      "obj_val 1.16083505609\n",
      "obj_val 1.15785480221\n",
      "obj_val 1.15328803208\n",
      "obj_val 1.15236715316\n",
      "obj_val 1.14686116749\n",
      "obj_val 1.1382398186\n",
      "obj_val 1.13620105764\n",
      "obj_val 1.1240686681\n",
      "obj_val 1.12356571507\n",
      "obj_val 1.11851532127\n",
      "obj_val 1.11336909212\n",
      "obj_val 1.11423431613\n",
      "obj_val 1.11086189177\n",
      "obj_val 1.1087833721\n",
      "obj_val 1.11006550366\n",
      "obj_val 1.10796163118\n",
      "obj_val 1.10659299541\n",
      "obj_val 1.10580899264\n",
      "obj_val 1.10751593211\n",
      "obj_val 1.10502677736\n",
      "obj_val 1.10364573625\n",
      "obj_val 1.10204746832\n",
      "obj_val 1.10110503866\n",
      "obj_val 1.10030570782\n",
      "obj_val 1.09738428453\n",
      "obj_val 1.09550497801\n",
      "obj_val 1.09568428439\n",
      "obj_val 1.09302861578\n",
      "obj_val 1.08940111068\n",
      "obj_val 1.08863046029\n",
      "obj_val 1.08373627752\n",
      "obj_val 1.07874222262\n",
      "obj_val 1.07454656868\n",
      "obj_val 1.06652271348\n",
      "obj_val 1.04862866579\n",
      "obj_val 1.05895104277\n",
      "obj_val 1.03871104494\n",
      "obj_val 1.02622940841\n",
      "obj_val 1.03396099439\n",
      "obj_val 1.02126127786\n",
      "obj_val 1.01708297965\n",
      "obj_val 1.01504065722\n",
      "obj_val 1.01431588482\n",
      "obj_val 1.01378325996\n",
      "obj_val 1.01197819366\n",
      "obj_val 1.01159171129\n",
      "obj_val 1.0117794137\n",
      "obj_val 1.01052416837\n",
      "obj_val 1.00888351147\n",
      "obj_val 1.00838038688\n",
      "obj_val 1.00616172072\n",
      "obj_val 1.00362535623\n",
      "obj_val 1.00246980215\n",
      "obj_val 1.00196237041\n",
      "obj_val 1.00080543888\n",
      "\n",
      "n_hidden = 80\n",
      "obj_val 1.34595190138\n",
      "obj_val 1.34595190138\n",
      "obj_val 3.95604832808\n",
      "obj_val 1.35910066035\n",
      "obj_val 1.30343026963\n",
      "obj_val 1.30143343899\n",
      "obj_val 1.28390431699\n",
      "obj_val 1.26388283529\n",
      "obj_val 1.26026030007\n",
      "obj_val 1.2522789707\n",
      "obj_val 1.24219090621\n",
      "obj_val 1.2340831701\n",
      "obj_val 1.22229660553\n",
      "obj_val 1.21727519109\n",
      "obj_val 1.22388603422\n",
      "obj_val 1.21147177892\n",
      "obj_val 1.20424118852\n",
      "obj_val 1.19915090039\n",
      "obj_val 1.19560182557\n",
      "obj_val 1.18945579694\n",
      "obj_val 1.18561739632\n",
      "obj_val 1.17650052062\n",
      "obj_val 1.16904902376\n",
      "obj_val 1.16303311195\n",
      "obj_val 1.15504293427\n",
      "obj_val 1.1522975388\n",
      "obj_val 1.15058917077\n",
      "obj_val 1.14718474965\n",
      "obj_val 1.14436246717\n",
      "obj_val 1.1398481912\n",
      "obj_val 1.13853515052\n",
      "obj_val 1.15371420612\n",
      "obj_val 1.13719791013\n",
      "obj_val 1.13515706966\n",
      "obj_val 1.13435216042\n",
      "obj_val 1.13154342275\n",
      "obj_val 1.13075902049\n",
      "obj_val 1.12989476035\n",
      "obj_val 1.12748856765\n",
      "obj_val 1.12686566156\n",
      "obj_val 1.12330843502\n",
      "obj_val 1.11958824568\n",
      "obj_val 1.11633944628\n",
      "obj_val 1.11141144631\n",
      "obj_val 1.10945131311\n",
      "obj_val 1.10501241974\n",
      "obj_val 1.11256167596\n",
      "obj_val 1.10376109215\n",
      "obj_val 1.10144283839\n",
      "obj_val 1.09756658305\n",
      "obj_val 1.09342893156\n",
      "obj_val 1.0958771714\n",
      "obj_val 1.0917139496\n",
      "obj_val 1.08893974404\n",
      "obj_val 1.08797833064\n",
      "obj_val 1.09618904683\n",
      "obj_val 1.08713021448\n",
      "obj_val 1.08589045911\n",
      "obj_val 1.08559338251\n",
      "obj_val 1.08611514667\n",
      "obj_val 1.08494641842\n",
      "obj_val 1.08390823421\n",
      "obj_val 1.08340493043\n",
      "obj_val 1.08129736838\n",
      "obj_val 1.07945153156\n",
      "obj_val 1.07963868744\n",
      "obj_val 1.07855856069\n",
      "obj_val 1.07701741551\n",
      "obj_val 1.07497593197\n",
      "obj_val 1.0745378444\n",
      "obj_val 1.07302839844\n",
      "obj_val 1.07211642039\n",
      "obj_val 1.07175708593\n",
      "obj_val 1.06984827457\n",
      "obj_val 1.06929474372\n",
      "obj_val 1.0692409612\n",
      "obj_val 1.06799873681\n",
      "obj_val 1.06601793779\n",
      "obj_val 1.0663594867\n",
      "obj_val 1.06480597627\n",
      "obj_val 1.06289183783\n",
      "obj_val 1.06246263797\n",
      "obj_val 1.05871495197\n",
      "obj_val 1.05717660312\n",
      "\n",
      "n_hidden = 90\n",
      "obj_val 1.45252009594\n",
      "obj_val 1.45252009594\n",
      "obj_val 4.41504259009\n",
      "obj_val 1.48990052033\n",
      "obj_val 1.28798115229\n",
      "obj_val 1.7395617103\n",
      "obj_val 1.28272356176\n",
      "obj_val 1.28008941517\n",
      "obj_val 1.26591720815\n",
      "obj_val 1.27657844128\n",
      "obj_val 1.262190362\n",
      "obj_val 1.27528142883\n",
      "obj_val 1.25876771921\n",
      "obj_val 1.25437566832\n",
      "obj_val 1.24984636489\n",
      "obj_val 1.24533207879\n",
      "obj_val 1.23740299541\n",
      "obj_val 1.22996091181\n",
      "obj_val 1.22208291603\n",
      "obj_val 1.20923972126\n",
      "obj_val 1.20731083794\n",
      "obj_val 1.1898758042\n",
      "obj_val 1.18245597956\n",
      "obj_val 1.24863893099\n",
      "obj_val 1.18134846633\n",
      "obj_val 1.181046806\n",
      "obj_val 1.17829439177\n",
      "obj_val 1.17206262811\n",
      "obj_val 1.1894416735\n",
      "obj_val 1.17055459786\n",
      "obj_val 1.16826063719\n",
      "obj_val 1.16726369203\n",
      "obj_val 1.16485341206\n",
      "obj_val 1.16249616103\n",
      "obj_val 1.15790788976\n",
      "obj_val 1.16082337599\n",
      "obj_val 1.15551145295\n",
      "obj_val 1.17018490685\n",
      "obj_val 1.15392507522\n",
      "obj_val 1.15132352997\n",
      "obj_val 1.15013545571\n",
      "obj_val 1.14638079035\n",
      "obj_val 1.14178780837\n",
      "obj_val 1.14854935398\n",
      "obj_val 1.14044999218\n",
      "obj_val 1.1394612645\n",
      "obj_val 1.13828703588\n",
      "obj_val 1.13658142301\n",
      "obj_val 1.13626621137\n",
      "obj_val 1.13689389382\n",
      "obj_val 1.13544648807\n",
      "obj_val 1.13411921575\n",
      "obj_val 1.13351330294\n",
      "obj_val 1.13279174278\n",
      "obj_val 1.13229316523\n",
      "obj_val 1.13025583444\n",
      "obj_val 1.12956277299\n",
      "obj_val 1.12635704952\n",
      "obj_val 1.12228372772\n",
      "obj_val 1.12483448722\n",
      "obj_val 1.12096181785\n",
      "obj_val 1.11882161487\n",
      "obj_val 1.11761228714\n",
      "obj_val 1.11611105549\n",
      "obj_val 1.11543083785\n",
      "obj_val 1.11559471765\n",
      "obj_val 1.11442406631\n",
      "obj_val 1.11286586721\n",
      "obj_val 1.11238256579\n",
      "obj_val 1.10940089485\n",
      "obj_val 1.10879503775\n",
      "obj_val 1.10510199939\n",
      "obj_val 1.10354638958\n",
      "obj_val 1.10269226106\n",
      "obj_val 1.1022720197\n",
      "obj_val 1.10142853492\n",
      "obj_val 1.10021492063\n",
      "obj_val 1.09843845667\n",
      "obj_val 1.09801024574\n",
      "obj_val 1.09687764689\n",
      "obj_val 1.09646558948\n",
      "obj_val 1.0953274345\n",
      "obj_val 1.09463116118\n",
      "obj_val 1.09449415997\n",
      "obj_val 1.09308952618\n",
      "obj_val 1.09199693563\n",
      "obj_val 1.09052605715\n",
      "obj_val 1.09019770919\n",
      "obj_val 1.08772468594\n",
      "\n",
      "n_hidden = 100\n",
      "obj_val 1.51191524841\n",
      "obj_val 1.51191524841\n",
      "obj_val 8.01474057343\n",
      "obj_val 1.44115114496\n",
      "obj_val 1.30811962879\n",
      "obj_val 1.96357578095\n",
      "obj_val 1.28097390667\n",
      "obj_val 1.2533538665\n",
      "obj_val 1.29508252518\n",
      "obj_val 1.24496832711\n",
      "obj_val 1.23685236533\n",
      "obj_val 1.22866552419\n",
      "obj_val 1.23010929217\n",
      "obj_val 1.22445523702\n",
      "obj_val 1.21911760157\n",
      "obj_val 1.21427042807\n",
      "obj_val 1.20691188986\n",
      "obj_val 1.20216396997\n",
      "obj_val 1.20838229225\n",
      "obj_val 1.20071583471\n",
      "obj_val 1.19818711597\n",
      "obj_val 1.1953805418\n",
      "obj_val 1.19233449313\n",
      "obj_val 1.19155056413\n",
      "obj_val 1.1876144498\n",
      "obj_val 1.18214331318\n",
      "obj_val 1.18064853761\n",
      "obj_val 1.17890570194\n",
      "obj_val 1.17769936552\n",
      "obj_val 1.1768940395\n",
      "obj_val 1.1738075703\n",
      "obj_val 1.17269160449\n",
      "obj_val 1.1686597383\n",
      "obj_val 1.16252629207\n",
      "obj_val 1.15974636539\n",
      "obj_val 1.15008728748\n",
      "obj_val 1.14405002572\n",
      "obj_val 1.13505692079\n",
      "obj_val 1.13163196396\n",
      "obj_val 1.11898503186\n",
      "obj_val 1.12240560306\n",
      "obj_val 1.11385949656\n",
      "obj_val 1.11336232414\n",
      "obj_val 1.11119014291\n",
      "obj_val 1.10849590051\n",
      "obj_val 1.10621204126\n",
      "obj_val 1.10494857557\n",
      "obj_val 1.10460393882\n",
      "obj_val 1.10322277893\n",
      "obj_val 1.10235855055\n",
      "obj_val 1.10149936451\n",
      "obj_val 1.1007774624\n",
      "obj_val 1.09985010398\n",
      "obj_val 1.09887948829\n",
      "obj_val 1.09822303696\n",
      "obj_val 1.09731473837\n",
      "obj_val 1.09726951782\n",
      "obj_val 1.09539716874\n",
      "obj_val 1.09169187798\n",
      "obj_val 1.08557545874\n",
      "obj_val 1.08731088123\n",
      "obj_val 1.08275617473\n",
      "obj_val 1.08230091896\n",
      "obj_val 1.08119254812\n",
      "obj_val 1.08004331363\n",
      "obj_val 1.079887607\n",
      "obj_val 1.07942601606\n",
      "obj_val 1.07839214915\n",
      "obj_val 1.0776723463\n",
      "obj_val 1.07950959963\n",
      "obj_val 1.07709316198\n",
      "obj_val 1.07626234115\n",
      "obj_val 1.07609750723\n",
      "obj_val 1.07467156683\n",
      "obj_val 1.07439272522\n",
      "obj_val 1.07218025763\n",
      "obj_val 1.06960353326\n",
      "\n",
      "optimum_n_hidden:  70\n",
      "optimum_lambda 0.9\n",
      "optimum_w1 [[ 0.11800872 -0.2163829   0.00482767  0.01021581 -0.06780549  0.16443628\n",
      "  -0.11968837 -0.00460849 -0.09156538 -0.22801181]\n",
      " [-0.01762567  0.01267729  0.23633917  0.22204089  0.0690309   0.09736347\n",
      "  -0.24190814  0.14295973 -0.0924552  -0.05618225]\n",
      " [ 0.20719515  0.15919494  0.1746753  -0.16948319 -0.11508499  0.15845999\n",
      "   0.10456192  0.17958412  0.0586517   0.12040523]\n",
      " [-0.19227826 -0.05561586  0.12056856 -0.05735752  0.0306913  -0.0143075\n",
      "  -0.27518849  0.0736695   0.03437297 -0.16377684]\n",
      " [-0.21043444 -0.19481698 -0.15017192  0.02121992  0.07761316  0.21558887\n",
      "   0.15788867  0.24079971 -0.1180363  -0.01270599]\n",
      " [-0.10167265 -0.17260423  0.15447749 -0.13757945  0.03778149  0.20828561\n",
      "   0.03966178  0.22484739  0.22508408  0.13159267]\n",
      " [-0.12595673 -0.14918385  0.04617713 -0.00772213 -0.20017551 -0.10464823\n",
      "  -0.1271505  -0.1900321   0.01056917  0.24871569]\n",
      " [ 0.24799978 -0.05794229  0.18687654  0.05702898  0.0570768   0.11843891\n",
      "  -0.15156362  0.2087393   0.00767355 -0.00640139]\n",
      " [-0.22662194  0.04301345  0.17162239 -0.08369308  0.05804037 -0.19281539\n",
      "   0.22675419  0.20805888 -0.00576132 -0.01585473]\n",
      " [ 0.20950159  0.10725404  0.10464844 -0.11021861  0.16519593 -0.01886123\n",
      "  -0.14296218  0.14897457 -0.17317099  0.14828859]\n",
      " [-0.03985224  0.04819434 -0.11167006  0.0725536  -0.17493194 -0.10860691\n",
      "  -0.03037497 -0.13299989 -0.23207603  0.09085686]\n",
      " [-0.21172926  0.07890559  0.014404    0.35142709 -0.15330616  0.19963735\n",
      "  -0.01893493 -0.24008502  0.13315845 -0.20955987]\n",
      " [-0.12103708  0.13926785 -0.12541852 -0.17605601 -0.02003159  0.12280859\n",
      "   0.08812075  0.13944599 -0.0911196   0.14123309]\n",
      " [-0.01677123 -0.09043489 -0.14072906 -0.08277027 -0.13148802 -0.36461004\n",
      "   0.09936212  0.21355695  0.05508524 -0.25279712]\n",
      " [ 0.22609254 -0.0981511   0.15560786  0.16709581 -0.0571991   0.24310717\n",
      "  -0.21598696 -0.1051821  -0.0911186  -0.01062671]\n",
      " [ 0.19621144 -0.13233855  0.11110223 -0.23288744 -0.13104871  0.16695218\n",
      "  -0.05958708 -0.26615196  0.09061685  0.09483841]\n",
      " [ 0.01774812  0.02924048 -0.01669365 -0.27948819  0.00883803 -0.28431876\n",
      "  -0.05523977  0.24754533  0.12973263  0.10124094]\n",
      " [-0.05192008 -0.07492987  0.05850232  0.21202186  0.06408748 -0.09464163\n",
      "  -0.23919557 -0.05316729 -0.17293916  0.18394058]\n",
      " [-0.15667557  0.0678493  -0.05046465  0.21071556 -0.00760038 -0.1530406\n",
      "   0.18637502 -0.07833355 -0.14910883 -0.07831219]\n",
      " [ 0.06353946  0.25818026  0.08054701 -0.19151506  0.03084695  0.11840065\n",
      "  -0.2379596  -0.06171768 -0.03487812  0.23627414]\n",
      " [-0.16274315  0.12471688  0.04532356  0.04444123 -0.11845958 -0.028579\n",
      "  -0.06948037 -0.20093138  0.17204631  0.23362429]\n",
      " [-0.24939555 -0.16727826  0.14356695 -0.17876216  0.23101695  0.23769825\n",
      "   0.06635556 -0.17239254  0.14567911  0.14466913]\n",
      " [-0.22106594  0.15541639  0.21050424  0.25726787 -0.22498416 -0.10420458\n",
      "   0.0979802  -0.12720294  0.40047682 -0.11508486]\n",
      " [ 0.10164469  0.04001075 -0.17513301  0.14524541  0.1360286   0.13376979\n",
      "  -0.12218955  0.10798136 -0.19194491  0.23943083]\n",
      " [ 0.13256074 -0.09601335 -0.15390312  0.15709361 -0.09472647  0.01449614\n",
      "  -0.10302128 -0.05256806 -0.25504508 -0.19678794]\n",
      " [ 0.03696548 -0.24934038 -0.1637977  -0.20196698 -0.00704825 -0.18674895\n",
      "  -0.21120985 -0.08328227 -0.14206832 -0.02596205]\n",
      " [-0.13922127 -0.16037381 -0.16062971 -0.16907222 -0.10098988 -0.01263676\n",
      "   0.20522758 -0.18359548  0.18833289  0.11222633]\n",
      " [-0.05316793 -0.03070376 -0.2159547   0.11003295 -0.05129878 -0.0574398\n",
      "  -0.05249851 -0.1335733   0.05681901 -0.16654585]\n",
      " [-0.12709606  0.04585924  0.03450406  0.0859981   0.10194011  0.14426799\n",
      "  -0.07608008  0.15435186  0.00305186 -0.1171688 ]\n",
      " [-0.07374983  0.02709409 -0.11270238 -0.03188245 -0.05722733 -0.1102481\n",
      "   0.18275986  0.08420563 -0.21896186  0.11670652]\n",
      " [ 0.17654804 -0.20859358 -0.00332303  0.15872942 -0.12521885 -0.09023439\n",
      "  -0.10254898  0.11083002  0.04125027  0.10767578]\n",
      " [-0.05410324 -0.00881066 -0.06148792 -0.10114486  0.259224    0.06016027\n",
      "  -0.0792735  -0.10940148  0.39170467 -0.21446543]\n",
      " [-0.10916656  0.19118267 -0.05143527 -0.09311763  0.13730244 -0.12725898\n",
      "  -0.21071786  0.0352337   0.1879309  -0.03821133]\n",
      " [ 0.16301484 -0.01181077  0.18942096  0.01509855  0.14975888 -0.17923945\n",
      "  -0.22774161  0.14492017  0.24690236  0.20555532]\n",
      " [ 0.11071515 -0.05809971  0.0865821  -0.18527578  0.19928107 -0.10591242\n",
      "  -0.06739882 -0.16560375  0.21060822 -0.16972877]\n",
      " [-0.16480601  0.22154457 -0.23671584 -0.03043487 -0.19083429  0.01960711\n",
      "  -0.1485518   0.23308102 -0.09929068  0.17735975]\n",
      " [ 0.15050275 -0.19190596 -0.10497722  0.00758551  0.24613004 -0.05916406\n",
      "   0.16756768 -0.2087152   0.06243652 -0.03423353]\n",
      " [-0.25668455 -0.09334456  0.2198621   0.09320435  0.08337387  0.16482548\n",
      "   0.09677953 -0.23127726  0.09434902 -0.23535811]\n",
      " [ 0.1629209   0.11313899  0.17311196  0.19496569 -0.04140602 -0.15537655\n",
      "   0.21459872 -0.1809427  -0.29004775 -0.07672983]\n",
      " [ 0.07345449  0.03865258  0.11321882 -0.02653337  0.05859624 -0.0507036\n",
      "   0.2988462   0.06490395 -0.47225691  0.01732105]\n",
      " [-0.13530055 -0.02605703 -0.08088467  0.21783658 -0.04520655  0.26955952\n",
      "   0.43385888 -0.19025365 -0.09966277  0.24464382]\n",
      " [ 0.03375816  0.30435363 -0.22440217 -0.30156068  0.09862942 -0.141657\n",
      "  -0.21889323  0.06731783  0.20812897 -0.2104321 ]\n",
      " [ 0.21901258  0.02878743  0.04560126 -0.12583411  0.04211921 -0.15843328\n",
      "  -0.00765755  0.18056482  0.09837875 -0.16540973]\n",
      " [ 0.2506531  -0.10567648 -0.07017664 -0.16992217 -0.21761963  0.03705005\n",
      "  -0.20937356  0.06947364  0.24151852  0.0068475 ]\n",
      " [-0.01371615  0.0678351  -0.11523866  0.10553849 -0.08502715 -0.15602372\n",
      "  -0.15620942  0.06607888 -0.10400163  0.20925943]\n",
      " [-0.07917252 -0.19044148 -0.06310213 -0.14210009 -0.02994136 -0.01656669\n",
      "  -0.00231501  0.25418637 -0.09331296  0.17199453]\n",
      " [ 0.11620889  0.21003985  0.16259974  0.03042304  0.13028249 -0.11199443\n",
      "   0.12530791  0.04956112  0.00442119 -0.23651033]\n",
      " [ 0.06395723  0.44010224  0.42665101  0.2127981  -0.04322457  0.08769134\n",
      "  -0.36816906 -0.07801776 -0.22693588 -0.11017316]\n",
      " [ 0.20780871  0.17887139 -0.17324576 -0.1739385  -0.12248116  0.11339561\n",
      "  -0.23367991 -0.06810691  0.12694453  0.21617231]\n",
      " [ 0.16565479 -0.21923227  0.0373056   0.19132637 -0.18883621 -0.21785352\n",
      "  -0.04498742  0.01692911  0.08281496  0.209725  ]\n",
      " [-0.20050978  0.36052224  0.44127916  0.26059718 -0.05428774  0.11017418\n",
      "   0.09204072 -0.02388815  0.14912406  0.22540737]\n",
      " [ 0.07779293 -0.34235531 -0.17296719  0.14650416 -0.10815359 -0.09580354\n",
      "   0.22756939  0.13079712 -0.5127724  -0.20253283]\n",
      " [-0.07443331  0.09033098 -0.09808013  0.11637188 -0.01352903 -0.00642679\n",
      "  -0.18472978  0.16043616  0.37680985  0.1726866 ]\n",
      " [ 0.05822002 -0.11595011 -0.10692199 -0.07621903 -0.20126171  0.22305998\n",
      "   0.11798256 -0.00530624  0.18053142 -0.20434773]\n",
      " [-0.15655697  0.07681018  0.07231192  0.26098611  0.03398485  0.09702126\n",
      "   0.1516436   0.34951585  0.07220504  0.19216002]\n",
      " [-0.05947603 -0.07144314 -0.02984165  0.23856916  0.05802583  0.15582305\n",
      "   0.04660415  0.02801184  0.23409725 -0.10376041]\n",
      " [ 0.17458102  0.02827363  0.04352278  0.20838935  0.00302036 -0.05186971\n",
      "   0.13990648  0.13034645 -0.18444203  0.14965719]\n",
      " [ 0.0894549  -0.15511997 -0.13859132  0.00474117 -0.17469817  0.13516058\n",
      "   0.02148602 -0.06809361  0.1648215   0.16504139]\n",
      " [-0.12429645  0.195153   -0.18707294 -0.21331212 -0.00896157 -0.05924314\n",
      "  -0.04496592  0.02461765 -0.08989472 -0.24749745]\n",
      " [ 0.24359894 -0.13039878 -0.00900446  0.08789521 -0.24497994 -0.07349714\n",
      "  -0.09977887  0.20855109  0.09583292 -0.07880608]\n",
      " [-0.2289299   0.01095289  0.029612   -0.14493137  0.08805201  0.2163713\n",
      "   0.16451045 -0.2279409   0.09458887 -0.12062376]\n",
      " [ 0.12699395  0.11853193 -0.06345867  0.18326297  0.19508995  0.15870364\n",
      "   0.21767475 -0.18233047  0.24402333 -0.03759053]\n",
      " [-0.23400856 -0.11400275  0.17620875 -0.16977727 -0.01501804 -0.12692349\n",
      "   0.04112509 -0.18213249 -0.02815506 -0.04867042]\n",
      " [-0.20574324  0.02206716  0.0195637  -0.1181613   0.19308762 -0.20920874\n",
      "  -0.02933545  0.02793187  0.15923892  0.16265433]\n",
      " [-0.23567596  0.16714459  0.1937562   0.05267638 -0.08388746 -0.12759862\n",
      "   0.21261321 -0.10063266  0.02505862  0.02695817]\n",
      " [ 0.10367646 -0.23970361 -0.20069129 -0.22082614 -0.02803359  0.14416861\n",
      "  -0.0299572  -0.2314342  -0.41833368  0.03139952]\n",
      " [-0.01012339  0.19864316  0.22950783 -0.23571633 -0.03723534 -0.00733994\n",
      "  -0.11279766 -0.24219108  0.0313006   0.23285563]\n",
      " [ 0.0514771   0.12894855  0.12323669  0.13732739  0.24043796  0.15874117\n",
      "   0.18492863  0.16531366 -0.23025708  0.05311848]\n",
      " [-0.01147662  0.23513708  0.24028928 -0.09365995  0.27016955  0.07952431\n",
      "  -0.2837845  -0.02811083  0.13996347 -0.25191338]\n",
      " [-0.1116711  -0.03127182  0.12811054  0.13052028  0.2366422  -0.21003454\n",
      "   0.03149104  0.17587026 -0.0303058  -0.05091282]]\n",
      "optimum_w2 [[-0.05696573 -0.34261158  0.13356318  0.00911824  0.12384848 -0.20067509\n",
      "  -0.10971464 -0.14690737  0.20098896  0.08244316  0.02858991 -0.32203034\n",
      "  -0.04057076 -0.2921832   0.05932631  0.08896143 -0.33362626 -0.02674095\n",
      "   0.12922846 -0.18948818  0.0695494   0.24742971 -0.44302531  0.31344959\n",
      "   0.00268455 -0.03538938  0.09337546 -0.16704133  0.14648224 -0.21343029\n",
      "  -0.09404192 -0.40868153  0.24947016  0.10076516 -0.1044612  -0.29080989\n",
      "  -0.02193213  0.10687122 -0.05919454  0.47207574  0.66528006 -0.43120454\n",
      "   0.1300239   0.2895467   0.11154659  0.13296921 -0.09065678 -0.71119966\n",
      "   0.26845139  0.13972622 -0.44884411  0.66223248 -0.39070117  0.11355367\n",
      "  -0.18732331  0.24449283  0.18689045  0.01513646  0.01468664  0.13144855\n",
      "   0.21179985  0.2922321  -0.24615437 -0.04102477  0.17799394  0.63354206\n",
      "  -0.31006298  0.22865812 -0.263215    0.01643022 -0.0391741 ]\n",
      " [-0.10221477  0.12369564  0.16393434  0.19101997 -0.1538194   0.16828609\n",
      "   0.15246818 -0.09646031  0.19575675  0.10650238  0.10409193  0.51204974\n",
      "   0.10985093  0.29481719 -0.15696594 -0.0491512   0.17377482  0.1270035\n",
      "   0.0035723   0.36916183  0.03915396 -0.02064099  0.33869768 -0.28465105\n",
      "  -0.26595534 -0.10320991  0.15331479 -0.11536055  0.04942737  0.10634141\n",
      "  -0.21822986  0.16450196  0.06728641 -0.05665551  0.21947886 -0.01407782\n",
      "  -0.21936678 -0.15323847 -0.26020796 -0.49056503 -0.53897474  0.56139341\n",
      "  -0.25372687 -0.03960581 -0.05962956 -0.10312818 -0.02628896  0.65159201\n",
      "  -0.09918737 -0.00661135  0.49188072 -0.85213766  0.43049359 -0.09165198\n",
      "   0.25825772  0.00223812 -0.15785096  0.12137191  0.18567302 -0.26791303\n",
      "   0.07022401  0.04865994  0.00252984 -0.13386157 -0.03369913 -0.35844744\n",
      "   0.04587106 -0.20267812  0.51130318  0.16965891 -0.09474237]]\n",
      "('\\nTotal time: ', 0.05100178321202596)\n",
      "\n",
      "-------------------- End of code ------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def initializeWeights(n_in,n_out):\n",
    "    \"\"\"\n",
    "    # initializeWeights return the random weights for Neural Network given the\n",
    "    # number of node in the input layer and output layer\n",
    "\n",
    "    # Input:\n",
    "    # n_in: number of nodes of the input layer\n",
    "    # n_out: number of nodes of the output layer\n",
    "       \n",
    "    # Output: \n",
    "    # W: matrix of random initial weights with size (n_out x (n_in + 1))\"\"\"\n",
    "    \n",
    "    epsilon = sqrt(6) / sqrt(n_in + n_out + 1);\n",
    "    W = (np.random.rand(n_out, n_in + 1)*2* epsilon) - epsilon;\n",
    "    return W\n",
    "\n",
    "    #Added by harsh the sigmoid function itself handles the input whether its scalar, a vector or a matrix\n",
    "    #no need for the for loop\n",
    "def sigmoid(z):\n",
    "    return (1 / (1 + np.exp(-1 * z)))    \n",
    "\n",
    "def nnObjFunction(params, *args):\n",
    "    #print(\"\\n--------------------START - nnObjFunction------------------\")\n",
    "    #obj_start_time = time.time()\n",
    "    \n",
    "    \"\"\"% nnObjFunction computes the value of objective function (negative log \n",
    "    %   likelihood error function with regularization) given the parameters \n",
    "    %   of Neural Networks, thetraining data, their corresponding training \n",
    "    %   labels and lambda - regularization hyper-parameter.\n",
    "\n",
    "    % Input:\n",
    "    % params: vector of weights of 2 matrices w1 (weights of connections from\n",
    "    %     input layer to hidden layer) and w2 (weights of connections from\n",
    "    %     hidden layer to output layer) where all of the weights are contained\n",
    "    %     in a single vector.\n",
    "    % n_input: number of node in input layer (not include the bias node)\n",
    "    % n_hidden: number of node in hidden layer (not include the bias node)\n",
    "    % n_class: number of node in output layer (number of classes in\n",
    "    %     classification problem\n",
    "    % training_data: matrix of training data. Each row of this matrix\n",
    "    %     represents the feature vector of a particular image\n",
    "    % training_label: the vector of truth label of training images. Each entry\n",
    "    %     in the vector represents the truth label of its corresponding image.\n",
    "    % lambda: regularization hyper-parameter. This value is used for fixing the\n",
    "    %     overfitting problem.\n",
    "       \n",
    "    % Output: \n",
    "    % obj_val: a scalar value representing value of error function\n",
    "    % obj_grad: a SINGLE vector of gradient value of error function\n",
    "    % NOTE: how to compute obj_grad\n",
    "    % Use backpropagation algorithm to compute the gradient of error function\n",
    "    % for each weights in weight matrices.\n",
    "\n",
    "    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "    % reshape 'params' vector into 2 matrices of weight w1 and w2\n",
    "    % w1: matrix of weights of connections from input layer to hidden layers.\n",
    "    %     w1(i, j) represents the weight of connection from unit j in input \n",
    "    %     layer to unit i in hidden layer.\n",
    "    % w2: matrix of weights of connections from hidden layer to output layers.\n",
    "    %     w2(i, j) represents the weight of connection from unit j in hidden \n",
    "    %     layer to unit i in output layer.\"\"\"\n",
    "    \n",
    "    n_input, n_hidden, n_class, training_data, training_label, lambdaval = args\n",
    "    \n",
    "    #print n_hidden\n",
    "    #print n_input\n",
    "    #Added by Harsh there was a mismatch in the number of hidden nodes.\n",
    "    w1 = params[0:(n_hidden) * (n_input + 1)].reshape( (n_hidden, (n_input + 1)))\n",
    "    w2 = params[((n_hidden) * (n_input + 1)):].reshape((n_class, (n_hidden + 1)))\n",
    "    obj_val = 0  \n",
    "    \n",
    "    #Your code here\n",
    "    \n",
    "    w1_trans = np.transpose(w1)\n",
    "    w2_trans = np.transpose(w2)\n",
    "\n",
    "    n_examples = training_data.shape[0]\n",
    "    \n",
    "    #grad_w2 = output x hidden\n",
    "    #grad_w1 = output x hidden \n",
    "    grad_w1 = np.zeros((n_hidden + 1, n_input + 1)) #initialize to 0  \n",
    "    grad_w2 = np.zeros((n_class, n_hidden + 1)) #initialize to 0\n",
    "    \n",
    "    # === Add the (d+1)th bias attribute to training data as a column\n",
    "    ones = np.repeat(np.array([[1]]), n_examples, 0)\n",
    "    training_data = np.append(training_data, ones, 1)\n",
    "\n",
    "    x = training_data\n",
    "\n",
    "    z = sigmoid(np.dot(x, w1_trans))\n",
    "    \n",
    "    # Append bias (as a column vector [1,1,1...1]) to z\n",
    "    ones = np.repeat(np.array([[1]]), z.shape[0], 0)\n",
    "    z = np.append(z, ones, 1)\n",
    "    \n",
    "    o = sigmoid(np.dot(z, w2_trans))\n",
    "    y = training_label\n",
    "\n",
    "    #-----calculation for obj_grad-----\n",
    "    delta = np.subtract(o, y)\n",
    "\n",
    "    grad_w2 = np.add(grad_w2, (np.dot(delta.T, z)))\n",
    "        \n",
    "    prodzXsummation = (np.dot(delta, w2))*(z*(np.subtract(1.0, z)))\n",
    "\n",
    "    grad_w1 = np.add(grad_w1,(np.dot(prodzXsummation.T, x)))\n",
    "\n",
    "    j = y*(np.log(o)) + ((np.subtract(1.0, y))*(np.log(np.subtract(1.0, o))))\n",
    "    jsum = np.sum(j)\n",
    "        \n",
    "    obj_val = np.sum(jsum)\n",
    "        \n",
    "                 \n",
    "    # Make sure you reshape the gradient matrices to a 1D array. for instance \n",
    "    # if your gradient matrices are grad_w1 and grad_w2\n",
    "    # you would use code similar to the one below to create a flat array\n",
    "    # obj_grad = np.concatenate((grad_w1.flatten(), grad_w2.flatten()),0)\n",
    "    # obj_grad = np.array([])\n",
    "  \n",
    "    #grad_w1 = grad_w1 / n_examples\n",
    "    # Remove the last row from grad_w1 (to match the dimensions)\n",
    "    grad_w1=grad_w1[:-1,:]   \n",
    "    #grad_w2 = grad_w2 / n_examples   \n",
    "    \n",
    "    obj_val = (obj_val/n_examples)*-1        \n",
    "      \n",
    "    #---------------------------regularization----------------------------     \n",
    "    \n",
    "    refact_w1_sum = np.sum(np.square(w1))\n",
    "    refact_w2_sum = np.sum(np.square(w2))\n",
    "    final_reg_term =(lambdaval/(2*n_examples))*(refact_w1_sum+refact_w2_sum)\n",
    "    obj_val=obj_val+final_reg_term\n",
    "    \n",
    "    # Calculating the terms required for regularizing obj_grad\n",
    "    lambdaw1= w1*lambdaval\n",
    "    grad_w1 = (grad_w1+lambdaw1)/n_examples\n",
    "\n",
    "    lambdaw2= w2*lambdaval\n",
    "    grad_w2 = (grad_w2+lambdaw2)/n_examples\n",
    "    \n",
    "    #---------------------------/regularization----------------------------\n",
    "    \n",
    "    obj_grad = np.concatenate((grad_w1.flatten(), grad_w2.flatten()),0)\n",
    "    \n",
    "    #print \"obj_grad\", obj_grad\n",
    "    print \"obj_val\",  obj_val\n",
    "    \n",
    "    global run_count\n",
    "    run_count += 1\n",
    "    \n",
    "    #print(\"\\n--------------------END - nnObjFunction------------------\")\n",
    "    \n",
    "              \n",
    "    return (obj_val,obj_grad)\n",
    "\n",
    "\n",
    "def nnPredict(w1,w2,data):\n",
    "    \n",
    "    \"\"\"% nnPredict predicts the label of data given the parameter w1, w2 of Neural\n",
    "    % Network.\n",
    "\n",
    "    % Input:\n",
    "    % w1: matrix of weights of connections from input layer to hidden layers.\n",
    "    %     w1(i, j) represents the weight of connection from unit i in input \n",
    "    %     layer to unit j in hidden layer.\n",
    "    % w2: matrix of weights of connections from hidden layer to output layers.\n",
    "    %     w2(i, j) represents the weight of connection from unit i in input \n",
    "    %     layer to unit j in hidden layer.\n",
    "    % data: matrix of data. Each row of this matrix represents the feature \n",
    "    %       vector of a particular image\n",
    "       \n",
    "    % Output: \n",
    "    % label: a column vector of predicted labels\"\"\" \n",
    "    \n",
    "    labels = np.array([])\n",
    "        \n",
    "    w1_trans = np.transpose(w1)\n",
    "    \n",
    "    # === Add the (d+1)th bias attribute to input layer data as a column\n",
    "    ones = np.repeat(np.array([[1]]), data.shape[0], 0)\n",
    "    data = np.append(data, ones, 1)\n",
    "    x = data\n",
    "    \n",
    "    z = sigmoid(np.dot(x, w1_trans))\n",
    "    \n",
    "    # === Add the (d+1)th bias attribute to hidden layer data as a column\n",
    "    ones = np.repeat(np.array([[1]]), z.shape[0], 0)\n",
    "    z = np.append(z, ones, 1)\n",
    "\n",
    "    # Get the output\n",
    "    o = sigmoid(np.dot(z, w2.T))\n",
    "\n",
    "    # The prediction is the index of the output unit with the max o/p\n",
    "    labels = np.argmax(o, axis=1)\n",
    "           \n",
    "    return labels\n",
    "\n",
    "\n",
    "def runCode(initialWeights, args, opts, validation_data,validation_label, test_data, test_label):\n",
    "\n",
    "    global run_count\n",
    "    run_count = 0\n",
    "    \n",
    "    train_data = args[3]\n",
    "    train_label = args[4]\n",
    "\n",
    "    # ===== Train Neural Network using fmin_cg or minimize from scipy, optimize module. Check documentation for a working example\n",
    "    nn_params = minimize(nnObjFunction, initialWeights, jac=True, args=args, method='CG', options=opts)\n",
    "    \n",
    "    # In case you want to use fmin_cg, you may have to split the nnObjectFunction to two functions nnObjFunctionVal\n",
    "    # and nnObjGradient. Check documentation for this function before you proceed.\n",
    "    # nn_params, cost = fmin_cg(nnObjFunctionVal, initialWeights, nnObjGradient,args = args, maxiter = 50)\n",
    "    \n",
    "    \n",
    "    #====== We now have the trained weights ======\n",
    "    # Reshape nnParams from 1D vector into w1 and w2 matrices\n",
    "    w1 = nn_params.x[0:n_hidden * (n_input + 1)].reshape( (n_hidden, (n_input + 1)))\n",
    "    w2 = nn_params.x[(n_hidden * (n_input + 1)):].reshape((n_class, (n_hidden + 1)))\n",
    "    \n",
    "    # We need to convert the label matrices into column vectors\n",
    "    train_label = train_label.argmax(axis=1)\n",
    "    validation_label = validation_label.argmax(axis=1)\n",
    "    test_label = test_label.argmax(axis=1)\n",
    "    \n",
    "    \n",
    "    #====== Test the computed parameters ======\n",
    "    # Find the accuracy on the TRAINING Dataset\n",
    "    predicted_label = nnPredict(w1,w2,train_data)\n",
    "    training_set_accuracy = 100*np.mean((predicted_label == train_label).astype(float))\n",
    "    #print('\\n   Training set accuracy ==> ' + str(training_set_accuracy) + '%')\n",
    "    \n",
    "    # Find the accuracy on the VALIDATION Dataset\n",
    "    predicted_label = nnPredict(w1,w2,validation_data)\n",
    "    validation_set_accuracy = 100*np.mean((predicted_label == validation_label).astype(float))\n",
    "    #print('   Validation set accuracy ==> ' + str(validation_set_accuracy) + '%')\n",
    "    \n",
    "    #find the accuracy on the TEST Dataset\n",
    "    predicted_label = nnPredict(w1,w2,test_data)\n",
    "    test_set_accuracy = 100*np.mean((predicted_label == test_label).astype(float))\n",
    "    #print('   Test set accuracy: ==> ' + str(test_set_accuracy) + '%')\n",
    "\n",
    "    return w1, w2, training_set_accuracy, validation_set_accuracy, test_set_accuracy\n",
    "    \n",
    "\"\"\"************** Neural Network Script Starts here ********************************\"\"\"\n",
    "\n",
    "# Pickle file: Open it for writing\n",
    "pickle_file = open('params.pickle','wb')\n",
    "\n",
    "overall_start_time = time.time()\n",
    "train_data, train_label, validation_data,validation_label, test_data, test_label = get_data(file2)\n",
    "\n",
    "run_count = 0\n",
    "\n",
    "# Set the number of nodes in the input layer (not including bias unit)\n",
    "n_input = train_data.shape[1];\n",
    "\n",
    "# Number of nodes in the output layer are fixed as 10, because we've got 10 digits\n",
    "n_class = 2;\n",
    "\n",
    "\n",
    "# === Make CSV file === #\n",
    "with open(csv_file_path, 'w') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames = ['lambda','n_hidden','training_set_accuracy','validation_set_accuracy','test_set_accuracy','runs','time'])\n",
    "    writer.writeheader()\n",
    "\n",
    "\n",
    "# ====== Train Neural Network ====== #\n",
    "optimum_w1 = None\n",
    "optimum_w2 = None\n",
    "\n",
    "# ---- For different lambda values ---- #\n",
    "lambda_val = 0.0\n",
    "lambda_increment = 0.1\n",
    "n_hidden = 50\n",
    "\n",
    "# Initialize the weights into some random matrices\n",
    "initial_w1 = initializeWeights(n_input, n_hidden);\n",
    "initial_w2 = initializeWeights(n_hidden, n_class);\n",
    "    \n",
    "# Combine the 2 weight matrices into single column vector\n",
    "initialWeights = np.concatenate((initial_w1.flatten(), initial_w2.flatten()), 0)\n",
    "    \n",
    "max_accuracy = 0.0\n",
    "optimum_lambda = 0.0\n",
    "\n",
    "while lambda_val <= 1.0:\n",
    "    code_start_time = time.time()\n",
    "    print '\\nLambda = %.2f' %lambda_val\n",
    "    \n",
    "    # Run the minimize function\n",
    "    args = (n_input, n_hidden, n_class, train_data, train_label, lambda_val)\n",
    "    w1, w2, training_set_accuracy, validation_set_accuracy, test_set_accuracy = runCode(initialWeights, args, opts, validation_data, validation_label, test_data, test_label)\n",
    "    \n",
    "    # Print stuff to CSV\n",
    "    time_taken = (time.time() - code_start_time)/60.0\n",
    "    with open(csv_file_path, 'a') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames = ['lambda','n_hidden','training_set_accuracy','validation_set_accuracy','test_set_accuracy','runs','time'])\n",
    "        writer.writerow({'lambda': lambda_val, 'n_hidden': n_hidden, 'training_set_accuracy': training_set_accuracy, 'validation_set_accuracy': validation_set_accuracy, 'test_set_accuracy': test_set_accuracy, 'runs': run_count, 'time': time_taken})\n",
    "\n",
    "    # Get the most optimum lambda value\n",
    "    if max_accuracy < test_set_accuracy:\n",
    "        max_accuracy = test_set_accuracy\n",
    "        optimum_lambda = lambda_val\n",
    "    \n",
    "    # Increase the lambda value\n",
    "    lambda_val += lambda_increment\n",
    "    \n",
    "    \n",
    "# ---- For different n_hidden values ---- #\n",
    "lambda_val = optimum_lambda\n",
    "n_hidden = 10\n",
    "n_hidden_increment = 10\n",
    "n_hidden_upperlimit = 100\n",
    "\n",
    "max_accuracy = 0.0\n",
    "optimum_n_hidden = 0.0\n",
    "\n",
    "while n_hidden <= n_hidden_upperlimit:\n",
    "    code_start_time = time.time()\n",
    "    print '\\nn_hidden = %d' %n_hidden\n",
    "    \n",
    "    # Initialize the weights into some random matrices\n",
    "    initial_w1 = initializeWeights(n_input, n_hidden);\n",
    "    initial_w2 = initializeWeights(n_hidden, n_class);\n",
    "        \n",
    "    # Combine the 2 weight matrices into single column vector\n",
    "    initialWeights = np.concatenate((initial_w1.flatten(), initial_w2.flatten()), 0)\n",
    "    \n",
    "    # Run the minimize function\n",
    "    args = (n_input, n_hidden, n_class, train_data, train_label, lambda_val)\n",
    "    w1, w2, training_set_accuracy, validation_set_accuracy, test_set_accuracy = runCode(initialWeights, args, opts, validation_data, validation_label, test_data, test_label)\n",
    "    \n",
    "    # Print stuff to CSV\n",
    "    time_taken = (time.time() - code_start_time)/60.0\n",
    "    with open(csv_file_path, 'a') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames = ['lambda','n_hidden','training_set_accuracy','validation_set_accuracy','test_set_accuracy','runs','time'])\n",
    "        writer.writerow({'lambda': lambda_val, 'n_hidden': n_hidden, 'training_set_accuracy': training_set_accuracy, 'validation_set_accuracy': validation_set_accuracy, 'test_set_accuracy': test_set_accuracy, 'runs': run_count, 'time': time_taken})\n",
    "\n",
    "    # Get the most optimum lambda value\n",
    "    if max_accuracy < test_set_accuracy:\n",
    "        max_accuracy = test_set_accuracy\n",
    "        optimum_n_hidden = n_hidden\n",
    "        optimum_w1 = w1\n",
    "        optimum_w2 = w2\n",
    "    \n",
    "    # Increase the n_hidden value\n",
    "    n_hidden += n_hidden_increment\n",
    "\n",
    "print '\\noptimum_n_hidden: ', optimum_n_hidden\n",
    "print 'optimum_lambda', optimum_lambda\n",
    "print 'optimum_w1', optimum_w1\n",
    "print 'optimum_w2', optimum_w2\n",
    "\n",
    "# Dump everything into the file\n",
    "pickle.dump([optimum_n_hidden, optimum_w1, optimum_w2, optimum_lambda], pickle_file)\n",
    "\n",
    "# Close the pickle file\n",
    "pickle_file.close()\n",
    "print(\"\\nTotal time: \", (time.time() - overall_start_time)/60)\n",
    "print(\"\\n-------------------- End of code ------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
